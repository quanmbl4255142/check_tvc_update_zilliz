"""
Script ƒë·ªÉ l·ªçc c√°c URL h·ª£p l·ªá (kh√¥ng b·ªã 403) tr∆∞·ªõc khi upload l√™n Zilliz
S·ª≠ d·ª•ng HEAD request ƒë·ªÉ ki·ªÉm tra nhanh h∆°n
Ki·ªÉm tra c·∫£ HLS manifest URLs v·ªõi FFmpeg
"""

import argparse
import csv
import os
import sys
import time
import tempfile
import shutil
import subprocess
from typing import List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

try:
    import requests
except ImportError:
    print("‚ùå C·∫ßn c√†i ƒë·∫∑t requests: pip install requests")
    sys.exit(1)


def is_hls_manifest(url: str) -> bool:
    """Check if URL is an HLS manifest (.m3u8 or /manifest/hls)"""
    url_lower = url.lower()
    return (
        '.m3u8' in url_lower or 
        '/manifest/hls' in url_lower or
        'hls_variant' in url_lower or
        'hls' in url_lower and 'manifest' in url_lower
    )


def test_hls_with_ffmpeg(url: str, timeout: int = 15) -> Tuple[bool, str]:
    """
    Test HLS manifest URL v·ªõi FFmpeg ƒë·ªÉ xem c√≥ th·ªÉ extract frame kh√¥ng
    
    Returns:
        (success, error_message)
    """
    try:
        # Check if ffmpeg is available
        if not shutil.which('ffmpeg'):
            return (False, "FFmpeg not installed")
        
        # Create temp file for output
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
            tmp_path = tmp_file.name
        
        try:
            # Use FFmpeg to extract first frame from HLS stream
            cmd = [
                'ffmpeg',
                '-protocol_whitelist', 'file,http,https,tcp,tls,crypto',
                '-i', url,
                '-vframes', '1',
                '-ss', '0',
                '-y',  # overwrite
                '-loglevel', 'error',  # reduce noise
                tmp_path
            ]
            
            # Run FFmpeg with timeout
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=timeout,
                check=False
            )
            
            # Check if output file was created and is valid
            if result.returncode == 0 and os.path.exists(tmp_path) and os.path.getsize(tmp_path) > 0:
                return (True, "")
            else:
                # Get error from stderr
                error_msg = result.stderr.decode('utf-8', errors='ignore').strip()
                if not error_msg:
                    error_msg = "FFmpeg failed (unknown error)"
                return (False, f"FFmpeg error: {error_msg[:100]}")
                
        finally:
            # Clean up temp file
            try:
                if os.path.exists(tmp_path):
                    os.unlink(tmp_path)
            except Exception:
                pass
                
    except subprocess.TimeoutExpired:
        return (False, "FFmpeg timeout")
    except FileNotFoundError:
        return (False, "FFmpeg not found")
    except Exception as e:
        return (False, f"Unexpected error: {str(e)}")


def check_url_status(url: str, timeout: int = 10, check_hls: bool = True) -> Tuple[str, int, str]:
    """
    Ki·ªÉm tra status code c·ªßa URL b·∫±ng HEAD request (nhanh h∆°n GET)
    N·∫øu l√† HLS manifest, ki·ªÉm tra th√™m v·ªõi FFmpeg
    
    Returns:
        (url, status_code, error_message)
        status_code: 200 = OK, 403/404 = HTTP error, 0 = other error, -1 = HLS invalid
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': '*/*',
    }
    
    try:
        # Th·ª≠ HEAD request tr∆∞·ªõc (nhanh h∆°n, kh√¥ng download data)
        response = requests.head(url, headers=headers, timeout=timeout, allow_redirects=True)
        status = response.status_code
        
        # N·∫øu HEAD kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ (405), th·ª≠ GET v·ªõi stream
        if status == 405:
            response = requests.get(url, headers=headers, timeout=timeout, stream=True, allow_redirects=True)
            status = response.status_code
            response.close()
        
        # N·∫øu status 200 v√† l√† HLS manifest, ki·ªÉm tra th√™m v·ªõi FFmpeg
        if status == 200 and check_hls and is_hls_manifest(url):
            hls_valid, hls_error = test_hls_with_ffmpeg(url, timeout=timeout + 5)
            if not hls_valid:
                # HLS manifest kh√¥ng h·ª£p l·ªá, ƒë√°nh d·∫•u l√† -1
                return (url, -1, f"HLS manifest invalid: {hls_error}")
        
        return (url, status, "")
        
    except requests.exceptions.Timeout:
        return (url, 0, "Timeout")
    except requests.exceptions.ConnectionError:
        return (url, 0, "Connection error")
    except requests.exceptions.RequestException as e:
        return (url, 0, str(e))
    except Exception as e:
        return (url, 0, f"Unexpected error: {str(e)}")


def filter_urls(
    input_csv: str,
    output_csv: str,
    invalid_csv: str,
    column: str = "decoded_url",
    start: int = 0,
    end: int = None,
    max_workers: int = 10,
    timeout: int = 10,
    args = None
):
    """
    L·ªçc URLs t·ª´ CSV, lo·∫°i b·ªè c√°c URL b·ªã 403 ho·∫∑c l·ªói kh√°c
    """
    print(f"üìñ ƒê·ªçc URLs t·ª´ {input_csv}...")
    
    # ƒê·ªçc URLs
    urls: List[str] = []
    with open(input_csv, "r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        if column in reader.fieldnames:
            for row in reader:
                u = (row.get(column) or "").strip().strip('"')
                if u:
                    urls.append(u)
        else:
            # Fallback: first column
            f.seek(0)
            reader2 = csv.reader(f)
            for i, row in enumerate(reader2):
                if not row:
                    continue
                cell = row[0].strip().strip('"')
                if i == 0 and cell.lower() in {"decoded_url", "url", "tvc"}:
                    continue
                if cell:
                    urls.append(cell)
    
    if not urls:
        print("‚ùå Kh√¥ng t√¨m th·∫•y URL n√†o!")
        return
    
    # X√°c ƒë·ªãnh range
    if end is None or end > len(urls):
        end = len(urls)
    start = max(0, start)
    
    if start >= end:
        print("‚ùå Range kh√¥ng h·ª£p l·ªá!")
        return
    
    urls_to_check = urls[start:end]
    print(f"üìä Ki·ªÉm tra {len(urls_to_check)} URLs (index {start} ƒë·∫øn {end-1})...")
    print(f"‚öôÔ∏è  S·ª≠ d·ª•ng {max_workers} workers, timeout {timeout}s\n")
    
    # Ki·ªÉm tra URLs v·ªõi thread pool
    valid_urls = []
    invalid_urls = []
    
    stats = {
        "total": len(urls_to_check),
        "valid": 0,
        "403": 0,
        "404": 0,
        "hls_invalid": 0,
        "other_error": 0,
        "timeout": 0
    }
    
    t0 = time.time()
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        check_hls = not args.skip_hls_check if args and hasattr(args, 'skip_hls_check') else True
        future_to_url = {
            executor.submit(check_url_status, url, timeout, check_hls): url 
            for url in urls_to_check
        }
        
        # Process results as they complete
        for idx, future in enumerate(as_completed(future_to_url)):
            url, status, error = future.result()
            global_idx = start + idx
            
            if status == 200:
                valid_urls.append(url)
                stats["valid"] += 1
                print(f"‚úÖ [{global_idx}] {url[:60]}... - OK (200)")
            elif status == -1:
                # HLS manifest kh√¥ng h·ª£p l·ªá
                invalid_urls.append((url, -1, error))
                stats["hls_invalid"] += 1
                print(f"‚ùå [{global_idx}] {url[:60]}... - HLS invalid: {error}")
            elif status == 403:
                invalid_urls.append((url, 403, "Forbidden"))
                stats["403"] += 1
                print(f"‚ùå [{global_idx}] {url[:60]}... - 403 Forbidden")
            elif status == 404:
                invalid_urls.append((url, 404, "Not Found"))
                stats["404"] += 1
                print(f"‚ùå [{global_idx}] {url[:60]}... - 404 Not Found")
            elif status == 0:
                invalid_urls.append((url, 0, error))
                stats["timeout"] += 1
                print(f"‚ö†Ô∏è  [{global_idx}] {url[:60]}... - Error: {error}")
            else:
                invalid_urls.append((url, status, f"HTTP {status}"))
                stats["other_error"] += 1
                print(f"‚ö†Ô∏è  [{global_idx}] {url[:60]}... - HTTP {status}")
            
            # Progress update
            if (idx + 1) % 50 == 0:
                elapsed = time.time() - t0
                rate = (idx + 1) / elapsed if elapsed > 0 else 0
                remaining = (len(urls_to_check) - idx - 1) / rate if rate > 0 else 0
                print(f"\nüìä Progress: {idx+1}/{len(urls_to_check)} | Rate: {rate:.2f} URLs/s | ETA: {remaining/60:.1f} min\n")
    
    # Ghi k·∫øt qu·∫£
    print(f"\nüíæ Ghi k·∫øt qu·∫£...")
    
    # Valid URLs
    with open(output_csv, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([column])
        for url in valid_urls:
            writer.writerow([url])
    
    # Invalid URLs v·ªõi th√¥ng tin l·ªói
    with open(invalid_csv, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([column, "status_code", "error"])
        for url, status, error in invalid_urls:
            writer.writerow([url, status, error])
    
    # Summary
    total_time = time.time() - t0
    print("\n" + "="*60)
    print("‚úÖ HO√ÄN TH√ÄNH!")
    print("="*60)
    print(f"T·ªïng s·ªë URLs ki·ªÉm tra: {stats['total']}")
    print(f"‚úÖ URLs h·ª£p l·ªá (200): {stats['valid']} ({stats['valid']/stats['total']*100:.1f}%)")
    print(f"‚ùå URLs b·ªã 403: {stats['403']} ({stats['403']/stats['total']*100:.1f}%)")
    print(f"‚ùå URLs b·ªã 404: {stats['404']} ({stats['404']/stats['total']*100:.1f}%)")
    print(f"‚ùå HLS manifest kh√¥ng h·ª£p l·ªá: {stats['hls_invalid']} ({stats['hls_invalid']/stats['total']*100:.1f}%)")
    print(f"‚ö†Ô∏è  Timeout/L·ªói kh√°c: {stats['timeout'] + stats['other_error']} ({(stats['timeout'] + stats['other_error'])/stats['total']*100:.1f}%)")
    print(f"\n‚è±Ô∏è  Th·ªùi gian: {total_time/60:.1f} ph√∫t")
    print(f"üìÅ File h·ª£p l·ªá: {output_csv}")
    print(f"üìÅ File l·ªói: {invalid_csv}")
    print("="*60)


def main():
    parser = argparse.ArgumentParser(
        description="L·ªçc c√°c URL h·ª£p l·ªá (lo·∫°i b·ªè 403/404) tr∆∞·ªõc khi upload"
    )
    parser.add_argument(
        "--input",
        default="url-tvc.unique.csv",
        help="File CSV input (default: url-tvc.unique.csv)"
    )
    parser.add_argument(
        "--output",
        default="url-tvc.valid.csv",
        help="File CSV output ch·ª©a URLs h·ª£p l·ªá (default: url-tvc.valid.csv)"
    )
    parser.add_argument(
        "--invalid",
        default="url-tvc.invalid.csv",
        help="File CSV ch·ª©a URLs l·ªói (default: url-tvc.invalid.csv)"
    )
    parser.add_argument(
        "--column",
        default="decoded_url",
        help="T√™n c·ªôt ch·ª©a URLs (default: decoded_url)"
    )
    parser.add_argument(
        "--start",
        type=int,
        default=0,
        help="Index b·∫Øt ƒë·∫ßu (default: 0)"
    )
    parser.add_argument(
        "--end",
        type=int,
        default=None,
        help="Index k·∫øt th√∫c (default: all)"
    )
    parser.add_argument(
        "--workers",
        type=int,
        default=10,
        help="S·ªë l∆∞·ª£ng workers ƒë·ªìng th·ªùi (default: 10)"
    )
    parser.add_argument(
        "--timeout",
        type=int,
        default=10,
        help="Timeout cho m·ªói request (seconds, default: 10)"
    )
    parser.add_argument(
        "--skip-hls-check",
        action="store_true",
        help="B·ªè qua ki·ªÉm tra HLS manifest v·ªõi FFmpeg (nhanh h∆°n nh∆∞ng c√≥ th·ªÉ b·ªè s√≥t l·ªói)"
    )
    
    args = parser.parse_args()
    
    if not os.path.isfile(args.input):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {args.input}")
        sys.exit(1)
    
    # Check FFmpeg availability if HLS check is enabled
    if not args.skip_hls_check:
        if not shutil.which('ffmpeg'):
            print("‚ö†Ô∏è  WARNING: FFmpeg not found!")
            print("   HLS manifest URLs s·∫Ω kh√¥ng ƒë∆∞·ª£c ki·ªÉm tra k·ªπ.")
            print("   C√†i FFmpeg ƒë·ªÉ ki·ªÉm tra HLS URLs: https://ffmpeg.org/download.html")
            print("   Ho·∫∑c d√πng --skip-hls-check ƒë·ªÉ b·ªè qua ki·ªÉm tra HLS\n")
    
    filter_urls(
        args.input,
        args.output,
        args.invalid,
        args.column,
        args.start,
        args.end,
        args.workers,
        args.timeout,
        args
    )


if __name__ == "__main__":
    main()

