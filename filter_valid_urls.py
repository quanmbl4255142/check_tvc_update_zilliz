"""
Script Ä‘á»ƒ lá»c cÃ¡c URL há»£p lá»‡ (khÃ´ng bá»‹ 403) trÆ°á»›c khi upload lÃªn Zilliz
Sá»­ dá»¥ng HEAD request Ä‘á»ƒ kiá»ƒm tra nhanh hÆ¡n
"""

import argparse
import csv
import os
import sys
import time
from typing import List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

try:
    import requests
except ImportError:
    print("âŒ Cáº§n cÃ i Ä‘áº·t requests: pip install requests")
    sys.exit(1)


def check_url_status(url: str, timeout: int = 10) -> Tuple[str, int, str]:
    """
    Kiá»ƒm tra status code cá»§a URL báº±ng HEAD request (nhanh hÆ¡n GET)
    
    Returns:
        (url, status_code, error_message)
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': '*/*',
    }
    
    try:
        # Thá»­ HEAD request trÆ°á»›c (nhanh hÆ¡n, khÃ´ng download data)
        response = requests.head(url, headers=headers, timeout=timeout, allow_redirects=True)
        status = response.status_code
        
        # Náº¿u HEAD khÃ´ng Ä‘Æ°á»£c há»— trá»£ (405), thá»­ GET vá»›i stream
        if status == 405:
            response = requests.get(url, headers=headers, timeout=timeout, stream=True, allow_redirects=True)
            status = response.status_code
            response.close()
        
        return (url, status, "")
        
    except requests.exceptions.Timeout:
        return (url, 0, "Timeout")
    except requests.exceptions.ConnectionError:
        return (url, 0, "Connection error")
    except requests.exceptions.RequestException as e:
        return (url, 0, str(e))
    except Exception as e:
        return (url, 0, f"Unexpected error: {str(e)}")


def filter_urls(
    input_csv: str,
    output_csv: str,
    invalid_csv: str,
    column: str = "decoded_url",
    start: int = 0,
    end: int = None,
    max_workers: int = 10,
    timeout: int = 10
):
    """
    Lá»c URLs tá»« CSV, loáº¡i bá» cÃ¡c URL bá»‹ 403 hoáº·c lá»—i khÃ¡c
    """
    print(f"ğŸ“– Äá»c URLs tá»« {input_csv}...")
    
    # Äá»c URLs
    urls: List[str] = []
    with open(input_csv, "r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        if column in reader.fieldnames:
            for row in reader:
                u = (row.get(column) or "").strip().strip('"')
                if u:
                    urls.append(u)
        else:
            # Fallback: first column
            f.seek(0)
            reader2 = csv.reader(f)
            for i, row in enumerate(reader2):
                if not row:
                    continue
                cell = row[0].strip().strip('"')
                if i == 0 and cell.lower() in {"decoded_url", "url", "tvc"}:
                    continue
                if cell:
                    urls.append(cell)
    
    if not urls:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y URL nÃ o!")
        return
    
    # XÃ¡c Ä‘á»‹nh range
    if end is None or end > len(urls):
        end = len(urls)
    start = max(0, start)
    
    if start >= end:
        print("âŒ Range khÃ´ng há»£p lá»‡!")
        return
    
    urls_to_check = urls[start:end]
    print(f"ğŸ“Š Kiá»ƒm tra {len(urls_to_check)} URLs (index {start} Ä‘áº¿n {end-1})...")
    print(f"âš™ï¸  Sá»­ dá»¥ng {max_workers} workers, timeout {timeout}s\n")
    
    # Kiá»ƒm tra URLs vá»›i thread pool
    valid_urls = []
    invalid_urls = []
    
    stats = {
        "total": len(urls_to_check),
        "valid": 0,
        "403": 0,
        "404": 0,
        "other_error": 0,
        "timeout": 0
    }
    
    t0 = time.time()
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_url = {
            executor.submit(check_url_status, url, timeout): url 
            for url in urls_to_check
        }
        
        # Process results as they complete
        for idx, future in enumerate(as_completed(future_to_url)):
            url, status, error = future.result()
            global_idx = start + idx
            
            if status == 200:
                valid_urls.append(url)
                stats["valid"] += 1
                print(f"âœ… [{global_idx}] {url[:60]}... - OK (200)")
            elif status == 403:
                invalid_urls.append((url, 403, "Forbidden"))
                stats["403"] += 1
                print(f"âŒ [{global_idx}] {url[:60]}... - 403 Forbidden")
            elif status == 404:
                invalid_urls.append((url, 404, "Not Found"))
                stats["404"] += 1
                print(f"âŒ [{global_idx}] {url[:60]}... - 404 Not Found")
            elif status == 0:
                invalid_urls.append((url, 0, error))
                stats["timeout"] += 1
                print(f"âš ï¸  [{global_idx}] {url[:60]}... - Error: {error}")
            else:
                invalid_urls.append((url, status, f"HTTP {status}"))
                stats["other_error"] += 1
                print(f"âš ï¸  [{global_idx}] {url[:60]}... - HTTP {status}")
            
            # Progress update
            if (idx + 1) % 50 == 0:
                elapsed = time.time() - t0
                rate = (idx + 1) / elapsed if elapsed > 0 else 0
                remaining = (len(urls_to_check) - idx - 1) / rate if rate > 0 else 0
                print(f"\nğŸ“Š Progress: {idx+1}/{len(urls_to_check)} | Rate: {rate:.2f} URLs/s | ETA: {remaining/60:.1f} min\n")
    
    # Ghi káº¿t quáº£
    print(f"\nğŸ’¾ Ghi káº¿t quáº£...")
    
    # Valid URLs
    with open(output_csv, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([column])
        for url in valid_urls:
            writer.writerow([url])
    
    # Invalid URLs vá»›i thÃ´ng tin lá»—i
    with open(invalid_csv, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([column, "status_code", "error"])
        for url, status, error in invalid_urls:
            writer.writerow([url, status, error])
    
    # Summary
    total_time = time.time() - t0
    print("\n" + "="*60)
    print("âœ… HOÃ€N THÃ€NH!")
    print("="*60)
    print(f"Tá»•ng sá»‘ URLs kiá»ƒm tra: {stats['total']}")
    print(f"âœ… URLs há»£p lá»‡ (200): {stats['valid']} ({stats['valid']/stats['total']*100:.1f}%)")
    print(f"âŒ URLs bá»‹ 403: {stats['403']} ({stats['403']/stats['total']*100:.1f}%)")
    print(f"âŒ URLs bá»‹ 404: {stats['404']} ({stats['404']/stats['total']*100:.1f}%)")
    print(f"âš ï¸  Timeout/Lá»—i khÃ¡c: {stats['timeout'] + stats['other_error']} ({(stats['timeout'] + stats['other_error'])/stats['total']*100:.1f}%)")
    print(f"\nâ±ï¸  Thá»i gian: {total_time/60:.1f} phÃºt")
    print(f"ğŸ“ File há»£p lá»‡: {output_csv}")
    print(f"ğŸ“ File lá»—i: {invalid_csv}")
    print("="*60)


def main():
    parser = argparse.ArgumentParser(
        description="Lá»c cÃ¡c URL há»£p lá»‡ (loáº¡i bá» 403/404) trÆ°á»›c khi upload"
    )
    parser.add_argument(
        "--input",
        default="url-tvc.unique.csv",
        help="File CSV input (default: url-tvc.unique.csv)"
    )
    parser.add_argument(
        "--output",
        default="url-tvc.valid.csv",
        help="File CSV output chá»©a URLs há»£p lá»‡ (default: url-tvc.valid.csv)"
    )
    parser.add_argument(
        "--invalid",
        default="url-tvc.invalid.csv",
        help="File CSV chá»©a URLs lá»—i (default: url-tvc.invalid.csv)"
    )
    parser.add_argument(
        "--column",
        default="decoded_url",
        help="TÃªn cá»™t chá»©a URLs (default: decoded_url)"
    )
    parser.add_argument(
        "--start",
        type=int,
        default=0,
        help="Index báº¯t Ä‘áº§u (default: 0)"
    )
    parser.add_argument(
        "--end",
        type=int,
        default=None,
        help="Index káº¿t thÃºc (default: all)"
    )
    parser.add_argument(
        "--workers",
        type=int,
        default=10,
        help="Sá»‘ lÆ°á»£ng workers Ä‘á»“ng thá»i (default: 10)"
    )
    parser.add_argument(
        "--timeout",
        type=int,
        default=10,
        help="Timeout cho má»—i request (seconds, default: 10)"
    )
    
    args = parser.parse_args()
    
    if not os.path.isfile(args.input):
        print(f"âŒ File khÃ´ng tá»“n táº¡i: {args.input}")
        sys.exit(1)
    
    filter_urls(
        args.input,
        args.output,
        args.invalid,
        args.column,
        args.start,
        args.end,
        args.workers,
        args.timeout
    )


if __name__ == "__main__":
    main()

