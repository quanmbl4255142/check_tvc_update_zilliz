"""
Kafka Consumer x·ª≠ l√Ω video: Redis cache ‚Üí check_tvc ‚Üí Milvus
Lu·ªìng: Kafka ‚Üí Redis (cache check) ‚Üí Embedding & Search Milvus ‚Üí L∆∞u v√†o Milvus ‚Üí Update Redis
"""

import os
import json
import sys
import time
import hashlib
from typing import Optional, Dict, Tuple
from datetime import datetime

from kafka import KafkaConsumer
from kafka.errors import KafkaError
import redis
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn

from video_service import VideoService
from milvus_config import print_config

console = Console()

# Configuration
KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092")
KAFKA_TOPIC = os.getenv("KAFKA_TOPIC", "video_processing")
# Group ID c·ªë ƒë·ªãnh - n·∫øu mu·ªën reset offset, set RESET_OFFSET=true ho·∫∑c x√≥a consumer group
KAFKA_GROUP_ID = os.getenv("KAFKA_GROUP_ID", "video_processor_group")
RESET_OFFSET_ON_START = os.getenv("RESET_OFFSET", "false").lower() == "true"

# Retry configuration - Import t·ª´ timeout_config
try:
    from timeout_config import (
        REDIS_SOCKET_CONNECT_TIMEOUT,
        REDIS_SOCKET_TIMEOUT,
        REDIS_HEALTH_CHECK_INTERVAL,
        REDIS_CONNECTION_RETRIES,
        REDIS_RETRY_DELAY,
        KAFKA_CONSUMER_TIMEOUT_MS,
        KAFKA_MAX_POLL_RECORDS,
        KAFKA_MAX_POLL_INTERVAL_MS,
        KAFKA_SESSION_TIMEOUT_MS,
        KAFKA_HEARTBEAT_INTERVAL_MS,
        CONSUMER_ERROR_RETRY_DELAY,
        CONSUMER_MAX_ERROR_WAIT,
    )
except ImportError:
    # Fallback
    REDIS_SOCKET_CONNECT_TIMEOUT = int(os.getenv("REDIS_SOCKET_CONNECT_TIMEOUT", "5"))
    REDIS_SOCKET_TIMEOUT = int(os.getenv("REDIS_SOCKET_TIMEOUT", "5"))
    REDIS_HEALTH_CHECK_INTERVAL = int(os.getenv("REDIS_HEALTH_CHECK_INTERVAL", "30"))
    REDIS_CONNECTION_RETRIES = int(os.getenv("REDIS_CONNECTION_RETRIES", "5"))
    REDIS_RETRY_DELAY = float(os.getenv("REDIS_RETRY_DELAY", "2"))
    KAFKA_CONSUMER_TIMEOUT_MS = int(os.getenv("KAFKA_CONSUMER_TIMEOUT_MS", "2000"))
    KAFKA_MAX_POLL_RECORDS = int(os.getenv("KAFKA_MAX_POLL_RECORDS", "10"))
    KAFKA_MAX_POLL_INTERVAL_MS = int(os.getenv("KAFKA_MAX_POLL_INTERVAL_MS", "300000"))
    KAFKA_SESSION_TIMEOUT_MS = int(os.getenv("KAFKA_SESSION_TIMEOUT_MS", "30000"))
    KAFKA_HEARTBEAT_INTERVAL_MS = int(os.getenv("KAFKA_HEARTBEAT_INTERVAL_MS", "10000"))
    CONSUMER_ERROR_RETRY_DELAY = int(os.getenv("CONSUMER_ERROR_RETRY_DELAY", "5"))
    CONSUMER_MAX_ERROR_WAIT = int(os.getenv("CONSUMER_MAX_ERROR_WAIT", "60"))

# Retry configuration (legacy - gi·ªØ ƒë·ªÉ backward compatibility)
MAX_RETRY_ATTEMPTS = int(os.getenv("MAX_RETRY_ATTEMPTS", "3"))
RETRY_DELAY_SECONDS = int(os.getenv("RETRY_DELAY_SECONDS", "5"))

REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
REDIS_DB = int(os.getenv("REDIS_DB", "0"))
REDIS_PASSWORD = os.getenv("REDIS_PASSWORD", None)

# Redis key prefixes
REDIS_KEY_PREFIX_VIDEO = "video:"
REDIS_KEY_PREFIX_UNIQUE_ID = "unique_id:"
REDIS_KEY_PREFIX_STATS = "stats:"

# Cache TTL (seconds) - 7 days
CACHE_TTL = int(os.getenv("CACHE_TTL", "604800"))

# Result TTL (seconds) - 30 ph√∫t (tƒÉng t·ª´ 5 ph√∫t ƒë·ªÉ ƒë·∫£m b·∫£o UI c√≥ ƒë·ªß th·ªùi gian l·∫•y k·∫øt qu·∫£)
RESULT_TTL = int(os.getenv("RESULT_TTL", "1800"))  # 30 ph√∫t

# Processing status TTL (seconds) - 1 gi·ªù (cho status "processing")
PROCESSING_STATUS_TTL = int(os.getenv("PROCESSING_STATUS_TTL", "3600"))  # 1 gi·ªù


def get_video_hash(video_url: str) -> str:
    """T·∫°o hash t·ª´ video URL ƒë·ªÉ d√πng l√†m key trong Redis"""
    return hashlib.md5(video_url.encode('utf-8')).hexdigest()


def connect_redis() -> redis.Redis:
    """K·∫øt n·ªëi Redis v·ªõi retry mechanism v√† connection pooling"""
    max_retries = REDIS_CONNECTION_RETRIES
    retry_delay = REDIS_RETRY_DELAY
    
    for attempt in range(max_retries):
        try:
            r = redis.Redis(
                host=REDIS_HOST,
                port=REDIS_PORT,
                db=REDIS_DB,
                password=REDIS_PASSWORD,
                decode_responses=True,
                socket_connect_timeout=REDIS_SOCKET_CONNECT_TIMEOUT,
                socket_timeout=REDIS_SOCKET_TIMEOUT,
                socket_keepalive=True,  # Keep connection alive
                health_check_interval=REDIS_HEALTH_CHECK_INTERVAL,
                retry_on_timeout=True,  # Retry on timeout
                retry_on_error=[redis.ConnectionError, redis.TimeoutError]
            )
            # Test connection
            r.ping()
            console.print(f"[green]‚úÖ Redis connected: {REDIS_HOST}:{REDIS_PORT}[/green]")
            return r
        except (redis.ConnectionError, redis.TimeoutError) as e:
            if attempt < max_retries - 1:
                console.print(f"[yellow]‚ö†Ô∏è  Redis connection attempt {attempt + 1}/{max_retries} failed: {e}[/yellow]")
                console.print(f"[dim]   Retrying in {retry_delay} seconds...[/dim]")
                time.sleep(retry_delay)
                retry_delay *= 1.5  # Exponential backoff
            else:
                console.print(f"[red]‚ùå Failed to connect to Redis after {max_retries} attempts: {e}[/red]")
                raise
        except Exception as e:
            console.print(f"[red]‚ùå Unexpected error connecting to Redis: {e}[/red]")
            raise


def connect_kafka() -> KafkaConsumer:
    """K·∫øt n·ªëi Kafka Consumer"""
    try:
        # N·∫øu mu·ªën reset offset, d√πng group_id m·ªõi (t·∫°o group m·ªõi s·∫Ω ƒë·ªçc t·ª´ latest)
        group_id = KAFKA_GROUP_ID
        if RESET_OFFSET_ON_START:
            group_id = f"{KAFKA_GROUP_ID}_reset_{int(time.time())}"
            console.print(f"[yellow]‚ö†Ô∏è  RESET_OFFSET=true: D√πng group_id m·ªõi: {group_id}[/yellow]")
            console.print(f"[yellow]   Consumer s·∫Ω ƒë·ªçc t·ª´ latest offset (ch·ªâ message m·ªõi)[/yellow]")
        
        consumer = KafkaConsumer(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            group_id=group_id,  # Group ID
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            key_deserializer=lambda k: k.decode('utf-8') if k else None,
            auto_offset_reset='latest',  # Ch·ªâ ƒë·ªçc message m·ªõi (kh√¥ng ƒë·ªçc message c≈©)
            enable_auto_commit=False,  # Manual commit - ch·ªâ commit sau khi x·ª≠ l√Ω xong
            consumer_timeout_ms=KAFKA_CONSUMER_TIMEOUT_MS,
            max_poll_records=KAFKA_MAX_POLL_RECORDS,
            max_poll_interval_ms=KAFKA_MAX_POLL_INTERVAL_MS,
            session_timeout_ms=KAFKA_SESSION_TIMEOUT_MS,
            heartbeat_interval_ms=KAFKA_HEARTBEAT_INTERVAL_MS,
            api_version=(0, 10, 1)  # Ch·ªâ ƒë·ªãnh API version ƒë·ªÉ nh·∫•t qu√°n v·ªõi producer
        )
        
        # Subscribe topic
        consumer.subscribe([KAFKA_TOPIC])
        console.print(f"[yellow]Subscribing to topic: {KAFKA_TOPIC}...[/yellow]")
        
        # ƒê·ª£i assignment (topic c√≥ th·ªÉ ch∆∞a t·ªìn t·∫°i, s·∫Ω ƒë∆∞·ª£c t·∫°o khi c√≥ message ƒë·∫ßu ti√™n)
        import time as time_module
        console.print(f"[dim]Waiting for partition assignment (topic may be auto-created on first message)...[/dim]")
        timeout = time_module.time() + 10
        assignment_received = False
        poll_attempts = 0
        while time_module.time() < timeout and poll_attempts < 50:
            consumer.poll(timeout_ms=200)
            poll_attempts += 1
            if consumer.assignment():
                assignment_received = True
                break
        
        if assignment_received:
            partitions = [p.partition for p in consumer.assignment()]
            console.print(f"[green]‚úÖ Assigned to partitions: {partitions}[/green]")
        else:
            console.print(f"[yellow]‚ö†Ô∏è  No partitions assigned yet (topic may not exist, will wait for messages)[/yellow]")
        
        console.print(f"[green]‚úÖ Kafka consumer connected: {KAFKA_BOOTSTRAP_SERVERS}[/green]")
        console.print(f"[cyan]üì® Topic: {KAFKA_TOPIC}, Group: {group_id}[/cyan]")
        console.print(f"[dim]   Auto offset reset: LATEST (will only read NEW messages)[/dim]")
        if not RESET_OFFSET_ON_START:
            console.print(f"[dim]   üí° Tip: ƒê·ªÉ reset offset, set RESET_OFFSET=true ho·∫∑c ch·∫°y:[/dim]")
            console.print(f"[dim]      docker exec -it kafka kafka-consumer-groups --bootstrap-server localhost:9092 --group {KAFKA_GROUP_ID} --topic {KAFKA_TOPIC} --reset-offsets --to-latest --execute[/dim]")
        return consumer
    except Exception as e:
        console.print(f"[red]‚ùå Failed to connect to Kafka: {e}[/red]")
        raise


def get_stats_from_redis(redis_client: redis.Redis) -> Dict:
    """L·∫•y th·ªëng k√™ t·ª´ Redis"""
    try:
        total_before = redis_client.get(f"{REDIS_KEY_PREFIX_STATS}total_before") or "0"
        total_after = redis_client.get(f"{REDIS_KEY_PREFIX_STATS}total_after") or "0"
        total_added = redis_client.get(f"{REDIS_KEY_PREFIX_STATS}total_added") or "0"
        total_duplicates = redis_client.get(f"{REDIS_KEY_PREFIX_STATS}total_duplicates") or "0"
        
        return {
            "total_before": int(total_before),
            "total_after": int(total_after),
            "total_added": int(total_added),
            "total_duplicates": int(total_duplicates)
        }
    except Exception:
        return {
            "total_before": 0,
            "total_after": 0,
            "total_added": 0,
            "total_duplicates": 0
        }


def update_stats_in_redis(redis_client: redis.Redis, stats: Dict):
    """C·∫≠p nh·∫≠t th·ªëng k√™ v√†o Redis - s·ª≠ d·ª•ng Redis atomic operations ƒë·ªÉ tr√°nh race condition"""
    try:
        # S·ª≠ d·ª•ng Redis WATCH + MULTI + EXEC ƒë·ªÉ ƒë·∫£m b·∫£o atomicity v√† tr√°nh race condition
        # Ho·∫∑c s·ª≠ d·ª•ng Lua script ƒë·ªÉ ƒë·∫£m b·∫£o atomic operations
        pipe = redis_client.pipeline()
        
        # Set stats (overwrite)
        pipe.set(f"{REDIS_KEY_PREFIX_STATS}total_before", stats.get("total_before", 0))
        pipe.set(f"{REDIS_KEY_PREFIX_STATS}total_after", stats.get("total_after", 0))
        
        # Ch·ªâ increment n·∫øu gi√° tr·ªã > 0 ƒë·ªÉ tr√°nh tƒÉng kh√¥ng c·∫ßn thi·∫øt
        # S·ª≠ d·ª•ng INCRBY thay v√¨ INCR ƒë·ªÉ c√≥ th·ªÉ increment nhi·ªÅu h∆°n 1
        added = stats.get("added", 0)
        duplicates = stats.get("duplicates", 0)
        if added > 0:
            pipe.incrby(f"{REDIS_KEY_PREFIX_STATS}total_added", added)
        if duplicates > 0:
            pipe.incrby(f"{REDIS_KEY_PREFIX_STATS}total_duplicates", duplicates)
        
        # Execute t·∫•t c·∫£ operations trong m·ªôt transaction (atomic)
        pipe.execute()
    except Exception as e:
        console.print(f"[yellow]‚ö†Ô∏è  Failed to update stats: {e}[/yellow]")
        # Fallback: th·ª≠ l·∫°i v·ªõi retry
        try:
            time.sleep(0.1)
            pipe = redis_client.pipeline()
            pipe.set(f"{REDIS_KEY_PREFIX_STATS}total_before", stats.get("total_before", 0))
            pipe.set(f"{REDIS_KEY_PREFIX_STATS}total_after", stats.get("total_after", 0))
            if added > 0:
                pipe.incrby(f"{REDIS_KEY_PREFIX_STATS}total_added", added)
            if duplicates > 0:
                pipe.incrby(f"{REDIS_KEY_PREFIX_STATS}total_duplicates", duplicates)
            pipe.execute()
        except Exception as retry_error:
            console.print(f"[red]‚ùå Failed to update stats after retry: {retry_error}[/red]")


def process_video_message(
    message: Dict,
    redis_client: redis.Redis,
    video_service: VideoService
) -> Dict:
    """
    X·ª≠ l√Ω m·ªôt video message t·ª´ Kafka
    
    Lu·ªìng:
    1. L∆∞u initial status "processing" v√†o Redis (tr√°nh race condition)
    2. Ki·ªÉm tra Redis cache
    3. N·∫øu cache miss ‚Üí Embedding & Search Milvus
    4. N·∫øu TVC m·ªõi ‚Üí L∆∞u v√†o Milvus & L·∫•y unique_id m·ªõi
    5. N·∫øu TVC c≈© ‚Üí L·∫•y unique_id c≈©
    6. L∆∞u v√†o Redis cache
    7. Tr·∫£ v·ªÅ k·∫øt qu·∫£
    """
    request_id = message.get("request_id", "unknown")
    video_url = message.get("video_url", "")
    timestamp = message.get("timestamp", datetime.now().isoformat())
    
    # B∆∞·ªõc 0: L∆∞u initial status "processing" v√†o Redis ngay l·∫≠p t·ª©c (tr√°nh race condition)
    result_key = f"request_id:{request_id}"
    try:
        initial_status = {
            "status": "processing",
            "request_id": request_id,
            "video_url": video_url,
            "message": "Video ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω...",
            "timestamp": timestamp
        }
        redis_client.setex(
            result_key,
            PROCESSING_STATUS_TTL,  # TTL 1 gi·ªù cho processing status
            json.dumps(initial_status)
        )
        console.print(f"[dim]‚úÖ ƒê√£ l∆∞u initial status 'processing' v√†o Redis v·ªõi request_id: {request_id}[/dim]")
    except Exception as redis_error:
        console.print(f"[yellow]‚ö†Ô∏è  Kh√¥ng th·ªÉ l∆∞u initial status v√†o Redis: {redis_error}[/yellow]")
    
    if not video_url:
        # L∆∞u l·ªói v√†o Redis v·ªõi request_id
        try:
            result_key = f"request_id:{request_id}"
            error_data = {
                "status": "error",
                "request_id": request_id,
                "video_url": "",
                "message": "Thi·∫øu video_url trong message",
                "error": "Missing video_url"
            }
            redis_client.setex(
                result_key,
                RESULT_TTL,  # TTL 30 ph√∫t
                json.dumps(error_data)
            )
            console.print(f"[yellow]‚ö†Ô∏è  ƒê√£ l∆∞u l·ªói 'Thi·∫øu video_url' v√†o Redis v·ªõi request_id: {request_id}[/yellow]")
        except Exception as redis_error:
            console.print(f"[red]‚ùå Kh√¥ng th·ªÉ l∆∞u l·ªói v√†o Redis: {redis_error}[/red]")
        
        return {
            "status": "error",
            "message": "Thi·∫øu video_url",
            "request_id": request_id
        }
    
    video_hash = get_video_hash(video_url)
    cache_key = f"{REDIS_KEY_PREFIX_VIDEO}{video_hash}"
    
    console.print(f"\n[bold cyan]üìπ Processing video: {video_url[:80]}...[/bold cyan]")
    console.print(f"[dim]Request ID: {request_id}[/dim]")
    
    # B∆∞·ªõc 1: Ki·ªÉm tra Redis cache
    console.print("[yellow]üîç B∆∞·ªõc 1: Ki·ªÉm tra Redis cache...[/yellow]")
    cached_data = redis_client.get(cache_key)
    
    if cached_data:
        # Cache Hit
        console.print("[green]‚úÖ Cache Hit![/green]")
        try:
            cached_info = json.loads(cached_data)
            unique_id = cached_info.get("unique_id")
            is_new = cached_info.get("is_new", False)
            added_at = cached_info.get("added_at", timestamp)
            
            console.print(f"[cyan]üìã Unique ID t·ª´ cache: {unique_id}[/cyan]")
            console.print(f"[cyan]üìä Video {'M·ªöI' if is_new else 'C≈®'}: {video_url[:60]}...[/cyan]")
            
            # L·∫•y stats hi·ªán t·∫°i
            stats = get_stats_from_redis(redis_client)
            
            # L∆∞u k·∫øt qu·∫£ v·ªõi request_id ƒë·ªÉ API c√≥ th·ªÉ query
            result_key = f"request_id:{request_id}"
            similarity = cached_info.get("similarity", 0.0)
            result_data = {
                "status": "completed",
                "request_id": request_id,
                "video_url": video_url,
                "unique_id": unique_id,
                "is_new": is_new,
                "similarity": similarity,
                "added_at": added_at,
                "message": "Video ƒë√£ ƒë∆∞·ª£c th√™m m·ªõi v√†o Zilliz" if is_new else f"Video ƒë√£ c√≥ tr√™n d·ªØ li·ªáu (similarity: {similarity:.4f}) n√™n s·∫Ω kh√¥ng th√™m v√†o Zilliz",
                "cache_hit": True
            }
            redis_client.setex(
                result_key,
                RESULT_TTL,  # TTL 30 ph√∫t
                json.dumps(result_data)
            )
            
            return {
                "status": "success",
                "request_id": request_id,
                "video_url": video_url,
                "cache_hit": True,
                "unique_id": unique_id,
                "is_new": is_new,
                "added_at": added_at,
                "message": "Video ƒë√£ t·ªìn t·∫°i trong cache",
                "stats": stats
            }
        except Exception as e:
            console.print(f"[yellow]‚ö†Ô∏è  Error parsing cache data: {e}[/yellow]")
            # Fall through to cache miss processing
    
    # Cache Miss - C·∫ßn x·ª≠ l√Ω
    console.print("[yellow]‚ùå Cache Miss - C·∫ßn x·ª≠ l√Ω video[/yellow]")
    
    # B∆∞·ªõc 2: Embedding & Search Milvus
    console.print("[yellow]üîç B∆∞·ªõc 2: Embedding & Search Milvus...[/yellow]")
    
    try:
        # L·∫•y s·ªë l∆∞·ª£ng videos hi·ªán t·∫°i trong Milvus (tr∆∞·ªõc khi th√™m)
        stats_before = video_service.get_collection_count()
        
        # Ki·ªÉm tra duplicate v√† th√™m v√†o Milvus n·∫øu ch∆∞a c√≥
        result = video_service.check_and_add_video(video_url)
        
        if result["status"] == "error":
            # L∆∞u l·ªói v√†o Redis v·ªõi request_id ƒë·ªÉ API c√≥ th·ªÉ query
            try:
                result_key = f"request_id:{request_id}"
                error_data = {
                    "status": "error",
                    "request_id": request_id,
                    "video_url": video_url,
                    "message": result.get("message", "L·ªói khi x·ª≠ l√Ω video"),
                    "error": result.get("error", "Unknown error")
                }
                redis_client.setex(
                    result_key,
                    300,  # TTL 5 ph√∫t
                    json.dumps(error_data)
                )
                console.print(f"[yellow]‚ö†Ô∏è  ƒê√£ l∆∞u l·ªói v√†o Redis v·ªõi request_id: {request_id}[/yellow]")
            except Exception as redis_error:
                console.print(f"[red]‚ùå Kh√¥ng th·ªÉ l∆∞u l·ªói v√†o Redis: {redis_error}[/red]")
            
            return {
                "status": "error",
                "request_id": request_id,
                "video_url": video_url,
                "message": result.get("message", "L·ªói khi x·ª≠ l√Ω video"),
                "error": result.get("error")
            }
        
        is_new = result["is_new"]
        unique_id = result["unique_id"]
        similarity = result.get("similarity", 0.0)
        
        # L·∫•y s·ªë l∆∞·ª£ng videos sau khi th√™m
        stats_after = video_service.get_collection_count()
        
        # B∆∞·ªõc 3a ho·∫∑c 3b: L∆∞u unique_id
        if is_new:
            console.print(f"[green]‚úÖ TVC M·ªöI - ƒê√£ th√™m v√†o Milvus v·ªõi unique_id: {unique_id}[/green]")
        else:
            console.print(f"[yellow]‚ö†Ô∏è  TVC C≈® - ƒê√£ t·ªìn t·∫°i v·ªõi unique_id: {unique_id} (similarity: {similarity:.4f})[/yellow]")
        
        # B∆∞·ªõc 4: L∆∞u v√†o Redis cache
        console.print("[yellow]üíæ B∆∞·ªõc 4: L∆∞u v√†o Redis cache...[/yellow]")
        cache_data = {
            "unique_id": unique_id,
            "is_new": is_new,
            "video_url": video_url,
            "added_at": timestamp,
            "similarity": similarity
        }
        redis_client.setex(
            cache_key,
            CACHE_TTL,
            json.dumps(cache_data)
        )
        console.print("[green]‚úÖ ƒê√£ l∆∞u v√†o Redis cache[/green]")
        
        # L∆∞u k·∫øt qu·∫£ v·ªõi request_id ƒë·ªÉ API c√≥ th·ªÉ query
        result_key = f"request_id:{request_id}"
        result_data = {
            "status": "completed",
            "request_id": request_id,
            "video_url": video_url,
            "unique_id": unique_id,
            "is_new": is_new,
            "similarity": similarity,
            "added_at": timestamp,
            "message": "Video ƒë√£ ƒë∆∞·ª£c th√™m m·ªõi v√†o Zilliz" if is_new else f"Video ƒë√£ c√≥ tr√™n d·ªØ li·ªáu (similarity: {similarity:.4f}) n√™n s·∫Ω kh√¥ng th√™m v√†o Zilliz",
            "stats_before": stats_before,
            "stats_after": stats_after
        }
        redis_client.setex(
            result_key,
            RESULT_TTL,  # TTL 30 ph√∫t
            json.dumps(result_data)
        )
        console.print(f"[green]‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v·ªõi request_id: {request_id}[/green]")
        
        # C·∫≠p nh·∫≠t stats
        stats = {
            "total_before": stats_before,
            "total_after": stats_after,
            "added": 1 if is_new else 0,
            "duplicates": 0 if is_new else 1
        }
        update_stats_in_redis(redis_client, stats)
        
        # L·∫•y stats t·ªïng h·ª£p
        final_stats = get_stats_from_redis(redis_client)
        
        return {
            "status": "success",
            "request_id": request_id,
            "video_url": video_url,
            "cache_hit": False,
            "unique_id": unique_id,
            "is_new": is_new,
            "similarity": similarity,
            "added_at": timestamp,
            "message": f"Video {'ƒë√£ ƒë∆∞·ª£c th√™m m·ªõi' if is_new else 'ƒë√£ t·ªìn t·∫°i'}",
            "stats_before": stats_before,
            "stats_after": stats_after,
            "stats": final_stats
        }
        
    except Exception as e:
        console.print(f"[red]‚ùå Error processing video: {e}[/red]")
        import traceback
        traceback.print_exc()
        
        # L∆∞u l·ªói v√†o Redis v·ªõi request_id
        try:
            result_key = f"request_id:{request_id}"
            error_data = {
                "status": "error",
                "request_id": request_id,
                "video_url": video_url,
                "message": f"L·ªói khi x·ª≠ l√Ω video: {str(e)}",
                "error": str(e)
            }
            redis_client.setex(
                result_key,
                RESULT_TTL,  # TTL 30 ph√∫t
                json.dumps(error_data)
            )
        except:
            pass  # Ignore Redis errors
        return {
            "status": "error",
            "request_id": request_id,
            "video_url": video_url,
            "message": f"L·ªói khi x·ª≠ l√Ω video: {str(e)}",
            "error": str(e)
        }


def main():
    """Main consumer loop"""
    console.print("[bold cyan]üöÄ Starting Video Consumer[/bold cyan]")
    console.print("=" * 60)
    
    # Print configuration
    print_config()
    console.print(f"\n[cyan]üì° Kafka: {KAFKA_BOOTSTRAP_SERVERS}[/cyan]")
    console.print(f"[cyan]üì® Topic: {KAFKA_TOPIC}, Group: {KAFKA_GROUP_ID}[/cyan]")
    console.print(f"[cyan]üî¥ Redis: {REDIS_HOST}:{REDIS_PORT}[/cyan]")
    console.print("=" * 60)
    
    # Connect to services
    try:
        redis_client = connect_redis()
        kafka_consumer = connect_kafka()
        video_service = VideoService()
    except Exception as e:
        console.print(f"[red]‚ùå Failed to initialize services: {e}[/red]")
        sys.exit(1)
    
    console.print("\n[green]‚úÖ All services connected! Waiting for messages...[/green]\n")
    console.print(f"[dim]Consumer will read from LATEST offset (only new messages)[/dim]")
    console.print(f"[yellow]üí° Tip: N·∫øu mu·ªën ƒë·ªçc l·∫°i message c≈©, reset offset: kafka-consumer-groups --bootstrap-server localhost:9092 --group {KAFKA_GROUP_ID} --topic {KAFKA_TOPIC} --reset-offsets --to-latest --execute[/yellow]\n")
    
    # Consumer loop
    try:
        processed_count = 0
        poll_count = 0
        while True:
            try:
                # Poll for messages (timeout t·ª´ config)
                message_pack = kafka_consumer.poll(timeout_ms=KAFKA_CONSUMER_TIMEOUT_MS)
                poll_count += 1
                
                if not message_pack:
                    # Log m·ªói 10 l·∫ßn poll ƒë·ªÉ bi·∫øt ƒëang ho·∫°t ƒë·ªông
                    if poll_count % 10 == 0:
                        console.print(f"[dim]Polling... (polled {poll_count} times, waiting for messages)[/dim]")
                    continue
                
                # C√≥ messages!
                total_messages = sum(len(msgs) for msgs in message_pack.values())
                console.print(f"\n[bold green]üì® Received {total_messages} message(s) from {len(message_pack)} partition(s)[/bold green]")
                
                # Process each partition
                for topic_partition, messages in message_pack.items():
                    console.print(f"[cyan]Processing partition {topic_partition.partition}...[/cyan]")
                    for message in messages:
                        request_id = message.value.get('request_id', 'unknown')
                        video_url = message.value.get('video_url', '')[:60]
                        message_offset = message.offset
                        message_partition = topic_partition.partition
                        
                        # Idempotency check - ki·ªÉm tra xem message ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a
                        idempotency_key = f"processed:{request_id}:{message_partition}:{message_offset}"
                        try:
                            if redis_client.get(idempotency_key):
                                console.print(f"[yellow]‚ö†Ô∏è  Message ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc ƒë√≥ (idempotency check): {request_id}[/yellow]")
                                # Commit ngay v√¨ ƒë√£ x·ª≠ l√Ω r·ªìi
                                kafka_consumer.commit()
                                continue
                        except Exception as idem_error:
                            console.print(f"[yellow]‚ö†Ô∏è  Idempotency check failed: {idem_error}[/yellow]")
                            # Continue processing anyway
                        
                        try:
                            console.print(f"[bold yellow]üîÑ Processing message:[/bold yellow]")
                            console.print(f"[yellow]   Request ID: {request_id}[/yellow]")
                            console.print(f"[yellow]   Video URL: {video_url}...[/yellow]")
                            console.print(f"[yellow]   Partition: {message_partition}, Offset: {message_offset}[/yellow]")
                            
                            # Process message
                            result = process_video_message(
                                message.value,
                                redis_client,
                                video_service
                            )
                            
                            # Ki·ªÉm tra xem k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o Redis ch∆∞a
                            result_key = f"request_id:{request_id}"
                            check_result = redis_client.get(result_key)
                            if check_result:
                                console.print(f"[green]‚úÖ ƒê√£ x√°c nh·∫≠n: K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o Redis v·ªõi key: {result_key}[/green]")
                            else:
                                console.print(f"[red]‚ùå C·∫¢NH B√ÅO: K·∫øt qu·∫£ CH∆ØA ƒë∆∞·ª£c l∆∞u v√†o Redis v·ªõi key: {result_key}[/red]")
                                console.print(f"[yellow]   Status: {result.get('status')}, Message: {result.get('message', 'N/A')[:100]}[/yellow]")
                            
                            # CH·ªà commit sau khi x·ª≠ l√Ω th√†nh c√¥ng (manual commit)
                            # N·∫øu c√≥ l·ªói, message s·∫Ω ƒë∆∞·ª£c retry
                            if result.get("status") in ["success", "error"]:
                                # ƒê√°nh d·∫•u message ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (idempotency)
                                try:
                                    redis_client.setex(idempotency_key, 86400, "1")  # TTL 24h
                                except Exception:
                                    pass  # Ignore idempotency save error
                                
                                kafka_consumer.commit()
                                processed_count += 1
                                console.print(f"[green]‚úÖ Committed offset for request_id: {request_id}[/green]")
                            else:
                                console.print(f"[yellow]‚ö†Ô∏è  Kh√¥ng commit offset v√¨ status kh√¥ng r√µ r√†ng: {result.get('status')}[/yellow]")
                            
                            # Print result summary
                            console.print("\n[bold]" + "=" * 60 + "[/bold]")
                            console.print(f"[bold green]‚úÖ Video processed #{processed_count}[/bold green]")
                            console.print(f"[cyan]Status: {result['status']}[/cyan]")
                            console.print(f"[cyan]Video URL: {result.get('video_url', '')[:80]}...[/cyan]")
                            
                            if result['status'] == 'success':
                                console.print(f"[green]Unique ID: {result.get('unique_id')}[/green]")
                                console.print(f"[green]Is New: {'C√ì' if result.get('is_new') else 'KH√îNG'}[/green]")
                                
                                if 'stats_before' in result:
                                    console.print(f"[yellow]üìä Stats Before: {result['stats_before']} videos[/yellow]")
                                    console.print(f"[yellow]üìä Stats After: {result['stats_after']} videos[/yellow]")
                                
                                if 'stats' in result:
                                    stats = result['stats']
                                    console.print(f"[cyan]üìà Total Added: {stats.get('total_added', 0)}[/cyan]")
                                    console.print(f"[cyan]üìà Total Duplicates: {stats.get('total_duplicates', 0)}[/cyan]")
                            
                            console.print("[bold]" + "=" * 60 + "[/bold]\n")
                            
                        except Exception as e:
                            console.print(f"[red]‚ùå Error processing message: {e}[/red]")
                            import traceback
                            traceback.print_exc()
                            
                            request_id = message.value.get("request_id", "unknown")
                            
                            # L∆∞u l·ªói v√†o Redis v·ªõi request_id ƒë·ªÉ API c√≥ th·ªÉ query
                            try:
                                result_key = f"request_id:{request_id}"
                                error_data = {
                                    "status": "error",
                                    "request_id": request_id,
                                    "video_url": message.value.get("video_url", ""),
                                    "message": f"L·ªói khi x·ª≠ l√Ω message: {str(e)}",
                                    "error": str(e),
                                    "retry_available": True  # ƒê√°nh d·∫•u c√≥ th·ªÉ retry
                                }
                                redis_client.setex(
                                    result_key,
                                    RESULT_TTL,  # TTL 30 ph√∫t
                                    json.dumps(error_data)
                                )
                                console.print(f"[yellow]‚ö†Ô∏è  ƒê√£ l∆∞u l·ªói v√†o Redis v·ªõi request_id: {request_id}[/yellow]")
                            except Exception as redis_error:
                                console.print(f"[red]‚ùå Kh√¥ng th·ªÉ l∆∞u l·ªói v√†o Redis: {redis_error}[/red]")
                            
                            # KH√îNG commit message l·ªói - ƒë·ªÉ c√≥ th·ªÉ retry sau
                            # V·ªõi manual commit, message s·∫Ω ƒë∆∞·ª£c retry t·ª± ƒë·ªông khi consumer restart
                            # Ho·∫∑c c√≥ th·ªÉ implement retry mechanism ph·ª©c t·∫°p h∆°n v·ªõi dead letter queue
                            console.print(f"[yellow]‚ö†Ô∏è  Kh√¥ng commit offset cho message l·ªói - s·∫Ω retry khi consumer restart[/yellow]")
                            console.print(f"[dim]   Message s·∫Ω ƒë∆∞·ª£c retry t·ª± ƒë·ªông v√¨ offset ch∆∞a ƒë∆∞·ª£c commit[/dim]")
                            
                            # ƒê·ª£i m·ªôt ch√∫t tr∆∞·ªõc khi ti·∫øp t·ª•c (tr√°nh spam retry)
                            time.sleep(RETRY_DELAY_SECONDS)
                            
                            continue
                
            except KeyboardInterrupt:
                console.print("\n[yellow]‚ö†Ô∏è  Interrupted by user[/yellow]")
                break
            except Exception as e:
                console.print(f"[red]‚ùå Error in consumer loop: {e}[/red]")
                import traceback
                traceback.print_exc()
                # Exponential backoff cho error recovery
                error_wait = min(CONSUMER_ERROR_RETRY_DELAY * (1.5 ** min(processed_count // 10, 5)), CONSUMER_MAX_ERROR_WAIT)
                console.print(f"[yellow]‚è≥ Waiting {error_wait:.1f}s before retrying...[/yellow]")
                time.sleep(error_wait)
                continue
    
    finally:
        console.print("\n[yellow]üõë Shutting down consumer...[/yellow]")
        kafka_consumer.close()
        console.print("[green]‚úÖ Consumer stopped[/green]")


if __name__ == "__main__":
    main()

