# FLOWCHART: Luá»“ng Lá»c TrÃ¹ng - search_duplicates_aggregated.py

## âœ¨ Cáº¬P NHáº¬T Má»šI (2025)

### CÃ¡c Cáº£i Tiáº¿n ChÃ­nh:
- âœ… **Video ID Extraction**: Há»— trá»£ 8 CDN má»›i (FlashTalking, FPT Play, Adnxs, VZ CDN, UpPremium, BlueAdss, Adsrvr, AIActiv)
- âœ… **Resolution Extraction**: Há»— trá»£ nhiá»u patterns má»›i (FlashTalking, Adnxs, VZ CDN, query params)
- âœ… **Best Quality Selection**: DÃ¹ng `resolution_score` (width Ã— height) thay vÃ¬ chá»‰ itag
- âœ… **Cross-chunk Detection**: PhÃ¡t hiá»‡n duplicates giá»¯a cÃ¡c chunks vá»›i threshold riÃªng
- âœ… **Path Validation**: DFS vá»›i validation Ä‘á»ƒ trÃ¡nh transitive closure

---

## Mermaid Flowchart - Tá»•ng Quan

```mermaid
flowchart TD
    Start([Báº¯t Ä‘áº§u]) --> Connect[ğŸ”Œ Káº¿t ná»‘i Milvus<br/>Load Collection]
    
    Connect --> CheckChunk{ğŸ“¦ Chunk Mode?}
    
    CheckChunk -->|CÃ³| QueryChunk[Query theo job_id range<br/>url_XXXX format<br/>Batch query Ä‘á»ƒ trÃ¡nh message size limit]
    CheckChunk -->|KhÃ´ng| QueryAll[Query táº¥t cáº£ videos<br/>Sá»­ dá»¥ng offset/limit + ID range]
    
    QueryChunk --> LoadData[ğŸ“¥ Load embeddings + URLs<br/>all_data = job_id, url, embedding]
    QueryAll --> LoadData
    
    LoadData --> BuildVideoInfo["ğŸ”§ XÃ¢y dá»±ng video_info map<br/>job_id to url, embedding"]
    
    BuildVideoInfo --> CheckSkipURL{"--skip_url_dedup?"}
    
    CheckSkipURL -->|CÃ³| SkipPreFilter[â­ï¸ Bá» qua Pre-filtering<br/>Giá»¯ táº¥t cáº£ videos]
    CheckSkipURL -->|KhÃ´ng| PreFilter[ğŸ” PRE-FILTERING]
    
    PreFilter --> ExtractVideoID[ğŸ“‹ Extract Video ID tá»« URL<br/>âœ¨ 8 CDN Ä‘Æ°á»£c há»— trá»£:<br/>- Google CDN, YouTube<br/>- FlashTalking, FPT Play<br/>- Adnxs, VZ CDN<br/>- UpPremium, BlueAdss<br/>- Adsrvr, AIActiv]
    
    ExtractVideoID --> GroupByID["ğŸ“Š NhÃ³m videos theo Video ID<br/>video_id_groups: video_id to list of job_ids"]
    
    GroupByID --> CheckChunkMode{Chunk Mode?}
    
    CheckChunkMode -->|CÃ³| CrossChunkCheck[ğŸ”— Kiá»ƒm tra Video ID<br/>trong chunks khÃ¡c<br/>Batch query Ä‘á»ƒ tá»‘i Æ°u]
    CheckChunkMode -->|KhÃ´ng| SelectBest[â­ Chá»n video tá»‘t nháº¥t<br/>trong má»—i group]
    
    CrossChunkCheck --> CheckExist{Video ID exists<br/>in other chunk<br/>with smaller job_id?}
    
    CheckExist -->|CÃ³| RemoveCrossChunk[ğŸ—‘ï¸ Loáº¡i bá» toÃ n bá»™ group<br/>ÄÃ£ tá»“n táº¡i á»Ÿ chunk khÃ¡c]
    CheckExist -->|KhÃ´ng| SelectBest
    
    RemoveCrossChunk --> Pass1
    
    SelectBest --> ExtractResolution[ğŸ“ Extract Resolution tá»« URL<br/>âœ¨ Há»— trá»£ nhiá»u patterns:<br/>- FlashTalking: _width_height_bitrate_fps<br/>- Adnxs: _width_height_bitratek<br/>- VZ CDN: play_1080p<br/>- Query params: ?width=1920&height=1080]
    
    ExtractResolution --> CalculateScore["ğŸ“Š TÃ­nh resolution_score<br/>score = width x height<br/>Hoáº·c itag náº¿u khÃ´ng cÃ³ resolution"]
    
    CalculateScore --> SortByQuality["ğŸ”¢ Sort videos:<br/>1. resolution_score DESC<br/>2. itag DESC<br/>3. job_id ASC"]
    
    SortByQuality --> SelectBestQuality[âœ… Chá»n video cÃ³ resolution cao nháº¥t<br/>Giá»¯ láº¡i trong group]
    
    SelectBestQuality --> RemoveDupURL[ğŸ—‘ï¸ XÃ³a URL duplicates<br/>Giá»¯ 1 video/group<br/>Loáº¡i bá» cÃ¡c video cÃ²n láº¡i]
    
    RemoveDupURL --> Pass1
    SkipPreFilter --> Pass1[ğŸ” PASS 1: TÃ¬m Duplicate Pairs]
    
    Pass1 --> BatchVideos[ğŸ“¦ Chia videos thÃ nh batches<br/>batch_size = 10 max<br/>Zilliz limit]
    
    BatchVideos --> ParallelSearch[âš¡ Parallel Search vá»›i threads<br/>num_threads threads<br/>Search trÃªn Milvus/Zilliz]
    
    ParallelSearch --> CollectPairs[ğŸ“‹ Thu tháº­p duplicate pairs<br/>job_id1, job_id2, similarity<br/>Thread-safe collection]
    
    CollectPairs --> FilterThreshold["âœ… Lá»c pairs:<br/>similarity >= threshold<br/>Validate score: 0.0 to 1.0"]
    
    FilterThreshold --> NormalizePairs["ğŸ”„ Normalize pairs<br/>Sort job_ids Ä‘á»ƒ trÃ¡nh trÃ¹ng<br/>Remove duplicate pairs"]
    
    NormalizePairs --> SeparatePairs["ğŸ“Š TÃ¡ch pairs:<br/>- within-chunk pairs<br/>- cross-chunk pairs"]
    
    SeparatePairs --> Pass2[ğŸ”— PASS 2: Clustering & Chá»n Originals]
    
    Pass2 --> ProcessCrossChunk[ğŸŒ Xá»­ lÃ½ Cross-chunk Duplicates]
    
    ProcessCrossChunk --> CheckCrossThreshold{"similarity >=<br/>cross_chunk_threshold?<br/>default: 0.98"}
    
    CheckCrossThreshold -->|CÃ³| CheckOriginal{"Original á»Ÿ<br/>chunk khÃ¡c?"}
    CheckCrossThreshold -->|KhÃ´ng| SkipCrossDup[â­ï¸ Bá» qua pair nÃ y<br/>Similarity quÃ¡ tháº¥p]
    
    CheckOriginal -->|CÃ³| MarkCrossDup[ğŸ·ï¸ ÄÃ¡nh dáº¥u duplicate<br/>náº¿u original á»Ÿ chunk khÃ¡c<br/>ThÃªm vÃ o cross_chunk_duplicates]
    CheckOriginal -->|KhÃ´ng| SkipCrossDup
    
    MarkCrossDup --> BuildGraph
    SkipCrossDup --> BuildGraph["ğŸ•¸ï¸ XÃ¢y dá»±ng Graph<br/>job_id to neighbors<br/>Chá»‰ within-chunk pairs"]
    
    BuildGraph --> BuildSimilarityDict["ğŸ“š XÃ¢y dá»±ng similarity lookup<br/>job_id1, job_id2 to similarity<br/>Dict Ä‘á»ƒ tá»‘i Æ°u lookup"]
    
    BuildSimilarityDict --> DFS["ğŸ” DFS vá»›i Path Validation<br/>Max path length = 2<br/>Path similarity >= threshold x 0.95<br/>TrÃ¡nh transitive closure"]
    
    DFS --> FindClusters["ğŸ“Š TÃ¬m Connected Components<br/>Má»—i cluster = 1 nhÃ³m duplicates<br/>Iterative DFS Ä‘á»ƒ trÃ¡nh recursion limit"]
    
    FindClusters --> ProcessClusters[ğŸ”„ Xá»­ lÃ½ tá»«ng Cluster]
    
    ProcessClusters --> ExtractResCluster[ğŸ“ Extract Resolution cho má»—i video<br/>trong cluster]
    
    ExtractResCluster --> SortByQualityCluster[ğŸ”¢ Sort videos trong cluster:<br/>1. resolution_score DESC<br/>2. job_id ASC]
    
    SortByQualityCluster --> SelectOriginal[âœ… Chá»n original<br/>Video cÃ³ resolution cao nháº¥t<br/>ThÃªm vÃ o unique_videos]
    
    SelectOriginal --> AddDuplicates[ğŸ“ ThÃªm duplicates vÃ o<br/>duplicates list<br/>Vá»›i similarity tá»« lookup dict]
    
    AddDuplicates --> CheckStandalone{"CÃ²n videos<br/>standalone?<br/>KhÃ´ng trong cluster"}
    
    CheckStandalone -->|CÃ³| AddStandalone[â• ThÃªm standalone videos<br/>vÃ o unique_videos<br/>KhÃ´ng cÃ³ duplicates]
    CheckStandalone -->|KhÃ´ng| AddCrossDup
    
    AddStandalone --> AddCrossDup["ğŸŒ ThÃªm cross-chunk duplicates<br/>vÃ o duplicates list<br/>Mark CROSS-CHUNK trong original_url"]
    
    AddCrossDup --> CheckAutoClean{"--auto_clean?"}
    
    CheckAutoClean -->|CÃ³| ValidateURL["ğŸ§¼ Kiá»ƒm tra URL há»£p lá»‡<br/>Loáº¡i bá» PNG/images<br/>Loáº¡i bá» URLs lá»—i<br/>Kiá»ƒm tra domain, extension"]
    CheckAutoClean -->|KhÃ´ng| WriteResults
    
    ValidateURL --> SeparateValid["ğŸ“Š TÃ¡ch valid/invalid URLs<br/>valid_videos vs invalid_urls"]
    
    SeparateValid --> WriteResults[ğŸ’¾ Ghi káº¿t quáº£]
    
    WriteResults --> WriteUnique[ğŸ“„ Ghi unique_csv<br/>Danh sÃ¡ch URLs unique<br/>decoded_url]
    
    WriteUnique --> WriteReport[ğŸ“‹ Ghi report_csv<br/>Duplicates vá»›i original mapping<br/>duplicate_url, original_url, similarity]
    
    WriteReport --> CheckInvalid{Invalid URLs?}
    
    CheckInvalid -->|CÃ³| WriteInvalid[ğŸ“„ Ghi invalid_csv<br/>Invalid URLs report<br/>url, job_id, reason]
    CheckInvalid -->|KhÃ´ng| PerformanceReport
    
    WriteInvalid --> PerformanceReport[ğŸ“Š Performance Report<br/>Timing, RAM, CPU<br/>Phase breakdown]
    
    PerformanceReport --> End([âœ… Káº¿t thÃºc])
    
    style Start fill:#90EE90
    style End fill:#FFB6C1
    style PreFilter fill:#FFE4B5
    style Pass1 fill:#ADD8E6
    style Pass2 fill:#DDA0DD
    style WriteResults fill:#F0E68C
    style ExtractVideoID fill:#E6E6FA
    style ExtractResolution fill:#E6E6FA
    style DFS fill:#FFB6C1
```

---

## Flowchart Chi Tiáº¿t - CÃ¡c Phase

```mermaid
flowchart LR
    subgraph Phase1["PHASE 1: LOAD DATA"]
        A1[ğŸ”Œ Connect Milvus] --> A2[ğŸ“¦ Load Collection]
        A2 --> A3{Chunk Mode?}
        A3 -->|CÃ³| A4[Query by job_id range<br/>Batch query 100 videos/batch]
        A3 -->|KhÃ´ng| A5[Query all videos<br/>offset/limit + ID range]
        A4 --> A6[ğŸ“¥ Load Embeddings + URLs]
        A5 --> A6
        A6 --> A7[ğŸ”§ Build video_info map]
    end
    
    subgraph Phase2["PHASE 2: PRE-FILTER"]
        B1{--skip_url_dedup?} -->|CÃ³| B2[â­ï¸ Skip Pre-filtering]
        B1 -->|KhÃ´ng| B3[ğŸ“‹ Extract Video ID<br/>8 CDN patterns]
        B3 --> B4[ğŸ“Š Group by Video ID]
        B4 --> B5{Chunk Mode?}
        B5 -->|CÃ³| B6[ğŸ”— Check cross-chunk<br/>Batch query other chunks]
        B5 -->|KhÃ´ng| B7[â­ Select Best Quality]
        B6 --> B8{Exists in<br/>other chunk?}
        B8 -->|CÃ³| B9[ğŸ—‘ï¸ Remove Group]
        B8 -->|KhÃ´ng| B7
        B7 --> B10[ğŸ“ Extract Resolution<br/>Multiple patterns]
        B10 --> B11[ğŸ“Š Calculate Score<br/>width Ã— height]
        B11 --> B12[ğŸ”¢ Sort & Select<br/>Highest resolution]
        B12 --> B13[ğŸ—‘ï¸ Remove Duplicates]
        B9 --> B13
        B2 --> B13
    end
    
    subgraph Phase3["PHASE 3: PASS 1 - FIND PAIRS"]
        C1[ğŸ“¦ Batch Videos<br/>max 10/batch] --> C2[âš¡ Parallel Search<br/>num_threads threads]
        C2 --> C3[ğŸ“‹ Collect Pairs<br/>Thread-safe]
        C3 --> C4[âœ… Filter Threshold<br/>similarity >= threshold]
        C4 --> C5[ğŸ”„ Normalize Pairs<br/>Remove duplicates]
        C5 --> C6[ğŸ“Š Separate Pairs<br/>within-chunk vs cross-chunk]
    end
    
    subgraph Phase4["PHASE 4: PASS 2 - CLUSTER"]
        D1{--skip_cross_chunk?} -->|CÃ³| D2[â­ï¸ Skip Cross-chunk]
        D1 -->|KhÃ´ng| D3[ğŸŒ Process Cross-chunk<br/>Check threshold 0.98]
        D3 --> D4[ğŸ·ï¸ Mark Cross-chunk Duplicates]
        D2 --> D5[ğŸ•¸ï¸ Build Graph<br/>job_id â†’ neighbors]
        D4 --> D5
        D5 --> D6[ğŸ“š Build Similarity Dict<br/>Optimize lookup]
        D6 --> D7[ğŸ” DFS with Validation<br/>Max path = 2<br/>Path sim >= threshold Ã— 0.95]
        D7 --> D8[ğŸ“Š Find Clusters<br/>Connected components]
        D8 --> D9[ğŸ”„ Process Clusters]
        D9 --> D10[ğŸ“ Extract Resolution]
        D10 --> D11[ğŸ”¢ Sort by Quality<br/>resolution_score DESC]
        D11 --> D12[âœ… Select Original<br/>Highest resolution]
        D12 --> D13[ğŸ“ Add Duplicates]
        D13 --> D14[â• Add Standalone]
        D14 --> D15[ğŸŒ Add Cross-chunk]
    end
    
    subgraph Phase5["PHASE 5: OUTPUT"]
        E1{--auto_clean?} -->|CÃ³| E2[ğŸ§¼ Validate URLs<br/>Remove PNG/images]
        E1 -->|KhÃ´ng| E3[ğŸ’¾ Write CSV]
        E2 --> E4[ğŸ“Š Separate Valid/Invalid]
        E4 --> E3
        E3 --> E5[ğŸ“„ unique_csv]
        E5 --> E6[ğŸ“‹ report_csv]
        E6 --> E7{Invalid URLs?}
        E7 -->|CÃ³| E8[ğŸ“„ invalid_csv]
        E7 -->|KhÃ´ng| E9[ğŸ“Š Performance Report]
        E8 --> E9
    end
    
    Phase1 --> Phase2
    Phase2 --> Phase3
    Phase3 --> Phase4
    Phase4 --> Phase5
```

---

## Decision Points Chi Tiáº¿t

```mermaid
flowchart TD
    subgraph Decisions["CÃ¡c Äiá»ƒm Quyáº¿t Äá»‹nh"]
        D1{ğŸ“¦ Chunk Mode?}
        D2{â­ï¸ --skip_url_dedup?}
        D3{ğŸ”— Video ID exists<br/>in other chunk<br/>with smaller job_id?}
        D4{ğŸŒ similarity >=<br/>cross_chunk_threshold?<br/>default: 0.98}
        D5{"ğŸ” Path similarity >=<br/>threshold x 0.95?<br/>Max path length = 2"}
        D6{ğŸ§¼ --auto_clean?}
        D7{âœ… URL valid?<br/>Not PNG/image<br/>Has video indicator}
        D8{ğŸ“Š Video in cluster?}
    end
    
    D1 -->|CÃ³| QueryByJobID[Query by job_id range<br/>Batch query 100/batch<br/>Handle message size limit]
    D1 -->|KhÃ´ng| QueryAll[Query all videos<br/>offset/limit + ID range]
    
    D2 -->|CÃ³| SkipPreFilter[â­ï¸ Skip Pre-filtering<br/>Giá»¯ táº¥t cáº£ videos]
    D2 -->|KhÃ´ng| DoPreFilter[ğŸ” Do Pre-filtering<br/>Extract Video ID<br/>Group & Select Best]
    
    D3 -->|CÃ³| RemoveGroup[ğŸ—‘ï¸ Remove entire group<br/>ÄÃ£ tá»“n táº¡i á»Ÿ chunk khÃ¡c]
    D3 -->|KhÃ´ng| KeepGroup[âœ… Keep group<br/>Select best quality]
    
    D4 -->|CÃ³| MarkAsDup[ğŸ·ï¸ Mark as duplicate<br/>náº¿u original á»Ÿ chunk khÃ¡c]
    D4 -->|KhÃ´ng| SkipPair[â­ï¸ Skip pair<br/>Similarity quÃ¡ tháº¥p]
    
    D5 -->|CÃ³| AddToCluster[âœ… Add to cluster<br/>Path similarity OK]
    D5 -->|KhÃ´ng| StopPath[â¹ï¸ Stop path<br/>Similarity dropped]
    
    D6 -->|CÃ³| ValidateURLs[ğŸ§¼ Validate URLs<br/>Remove invalid]
    D6 -->|KhÃ´ng| WriteAll[ğŸ’¾ Write all results]
    
    D7 -->|CÃ³| KeepURL[âœ… Keep URL<br/>Add to valid_videos]
    D7 -->|KhÃ´ng| RemoveURL[ğŸ—‘ï¸ Remove URL<br/>Add to invalid_urls]
    
    D8 -->|CÃ³| ProcessCluster[ğŸ”„ Process in cluster<br/>Select original]
    D8 -->|KhÃ´ng| AddStandalone[â• Add as standalone<br/>No duplicates]
```

---

## Data Flow

```mermaid
flowchart LR
    subgraph Input["ğŸ“¥ INPUT"]
        I1[(Milvus Collection<br/>job_id, url, embedding)]
        I2[Parameters:<br/>threshold, batch_size,<br/>chunk_start, chunk_end,<br/>skip_url_dedup, skip_cross_chunk]
    end
    
    subgraph Processing["âš™ï¸ PROCESSING"]
        P1[all_data:<br/>List of {job_id, url, embedding}]
        P2["video_info:<br/>Dict: job_id to {url, embedding}"]
        P3["video_id_groups:<br/>Dict: video_id to list of job_ids"]
        P4["duplicate_pairs:<br/>List of (job_id1, job_id2, similarity)"]
        P5["chunk_duplicate_pairs:<br/>Within-chunk pairs"]
        P6["cross_chunk_pairs:<br/>Cross-chunk pairs"]
        P7["similarity_lookup:<br/>Dict: (job_id1, job_id2) to similarity"]
        P8["graph:<br/>Dict: job_id to Set of neighbors"]
        P9["clusters:<br/>List of Set of job_ids"]
        P10[originals:<br/>Set of job_ids]
        P11[unique_videos:<br/>List of {url, job_id}]
        P12[duplicates:<br/>List of {duplicate_url, original_url, similarity}]
    end
    
    subgraph Output["ğŸ“¤ OUTPUT"]
        O1[(unique_csv:<br/>Unique URLs)]
        O2[(report_csv:<br/>Duplicates report)]
        O3[(invalid_csv:<br/>Invalid URLs<br/>if --auto_clean)]
    end
    
    I1 --> P1
    I2 --> P1
    P1 --> P2
    P2 --> P3
    P3 --> P2
    P2 --> P4
    P4 --> P5
    P4 --> P6
    P5 --> P7
    P7 --> P8
    P8 --> P9
    P9 --> P10
    P10 --> P11
    P9 --> P12
    P6 --> P12
    P11 --> O1
    P12 --> O2
    P2 --> O3
```

---

## Critical Logic Flow - Chi Tiáº¿t

```mermaid
flowchart TD
    Start --> Load[ğŸ“¥ Load Videos from Milvus]
    Load --> PreFilter{ğŸ” Pre-filter?<br/>--skip_url_dedup?}
    
    PreFilter -->|No| ExtractID[ğŸ“‹ Extract Video ID<br/>âœ¨ 8 CDN patterns:<br/>- Google CDN: gcdn_id_XXX<br/>- YouTube: youtube_XXX<br/>- FlashTalking: flashtalking_account_base<br/>- FPT Play: fptplay_id<br/>- Adnxs: adnxs_creative_uuid<br/>- VZ CDN: vzcdn_uuid<br/>- UpPremium: upremium_filename<br/>- BlueAdss: blueadss_path_filename<br/>- Adsrvr: adsrvr_filename<br/>- AIActiv: aiactiv_base]
    
    ExtractID --> Group[ğŸ“Š Group by Video ID<br/>video_id_groups]
    
    Group --> CheckChunk{ğŸ“¦ Chunk Mode?}
    
    CheckChunk -->|Yes| CheckExist{ğŸ”— Video ID exists<br/>in other chunk<br/>with smaller job_id?}
    CheckChunk -->|No| SelectBest
    
    CheckExist -->|Yes| Remove[ğŸ—‘ï¸ Remove Entire Group<br/>ÄÃ£ tá»“n táº¡i á»Ÿ chunk khÃ¡c]
    CheckExist -->|No| SelectBest[â­ Select Best Video]
    
    Remove --> Search
    
    SelectBest --> ExtractRes[ğŸ“ Extract Resolution<br/>âœ¨ Multiple patterns:<br/>- FlashTalking: _width_height_bitrate_fps<br/>- Adnxs: _width_height_bitratek<br/>- VZ CDN: play_1080p<br/>- Query params: ?width=1920&height=1080<br/>- Standard: 1920x1080, 1080p]
    
    ExtractRes --> CalcScore["ğŸ“Š Calculate Score<br/>resolution_score = width x height<br/>Fallback: itag"]
    
    CalcScore --> Sort[ğŸ”¢ Sort by:<br/>1. resolution_score DESC<br/>2. itag DESC<br/>3. job_id ASC]
    
    Sort --> KeepBest[âœ… Keep Best Quality<br/>Remove others in group]
    
    KeepBest --> Search
    PreFilter -->|Yes| Search[ğŸ” Search Duplicates<br/>Vector Similarity]
    
    Search --> FindPairs[ğŸ“‹ Find Duplicate Pairs<br/>Batch parallel search<br/>top_k results per video]
    
    FindPairs --> Separate{ğŸ“Š Within-chunk<br/>or Cross-chunk?}
    
    Separate -->|Cross-chunk| CheckSim{ğŸŒ Sim >=<br/>cross_chunk_threshold?<br/>default: 0.98}
    CheckSim -->|Yes| CheckOrig{Original á»Ÿ<br/>chunk khÃ¡c?}
    CheckSim -->|No| SkipCross
    CheckOrig -->|Yes| MarkDup[ğŸ·ï¸ Mark as Duplicate<br/>Add to cross_chunk_duplicates]
    CheckOrig -->|No| SkipCross[â­ï¸ Skip]
    MarkDup --> Cluster
    
    Separate -->|Within-chunk| Cluster[ğŸ•¸ï¸ Build Graph & Cluster]
    
    Cluster --> BuildDict[ğŸ“š Build Similarity Dict<br/>Optimize lookup]
    
    BuildDict --> DFS["ğŸ” DFS with Validation<br/>Max path length = 2<br/>Path similarity >= threshold x 0.95<br/>Prevent transitive closure"]
    
    DFS --> FindClusters[ğŸ“Š Find Clusters<br/>Connected components]
    
    FindClusters --> ProcessCluster[ğŸ”„ Process Each Cluster]
    
    ProcessCluster --> ExtractResCluster[ğŸ“ Extract Resolution<br/>for each video in cluster]
    
    ExtractResCluster --> CalcScoreCluster[ğŸ“Š Calculate Score<br/>for each video]
    
    CalcScoreCluster --> SortCluster[ğŸ”¢ Sort by Quality<br/>resolution_score DESC<br/>job_id ASC]
    
    SortCluster --> SelectOrig[âœ… Select Original<br/>Highest resolution<br/>Add to unique_videos]
    
    SelectOrig --> AddDups[ğŸ“ Add Duplicates<br/>to duplicates list]
    
    AddDups --> CheckStandalone{ğŸ“Š Standalone<br/>videos?}
    
    CheckStandalone -->|Yes| AddStandalone[â• Add Standalone<br/>to unique_videos]
    CheckStandalone -->|No| AddCross
    
    AddStandalone --> AddCross[ğŸŒ Add Cross-chunk<br/>to duplicates list]
    
    AddCross --> Clean{ğŸ§¼ Auto-clean?<br/>--auto_clean?}
    
    Clean -->|Yes| Validate[âœ… Validate URLs<br/>Remove PNG/images<br/>Remove invalid URLs]
    Validate --> Write
    Clean -->|No| Write[ğŸ’¾ Write Results]
    
    Write --> WriteUnique[ğŸ“„ Write unique_csv]
    WriteUnique --> WriteReport[ğŸ“‹ Write report_csv]
    WriteReport --> CheckInvalid{Invalid URLs?}
    CheckInvalid -->|Yes| WriteInvalid[ğŸ“„ Write invalid_csv]
    CheckInvalid -->|No| PerfReport
    WriteInvalid --> PerfReport[ğŸ“Š Performance Report]
    
    PerfReport --> End
    
    style Start fill:#90EE90
    style End fill:#FFB6C1
    style PreFilter fill:#FFE4B5
    style Search fill:#ADD8E6
    style Cluster fill:#DDA0DD
    style Write fill:#F0E68C
    style ExtractID fill:#E6E6FA
    style ExtractRes fill:#E6E6FA
    style DFS fill:#FFB6C1
```

---

## Video ID Extraction Patterns

```mermaid
flowchart TD
    URL[Input URL] --> Check1{Google CDN?}
    Check1 -->|Yes| G1[Extract: gcdn_id_XXXXX<br/>Pattern: /videoplayback/id/HEX_ID/]
    Check1 -->|No| Check2{YouTube?}
    
    Check2 -->|Yes| Y1[Extract: youtube_XXXXX<br/>Pattern: v=XXXXX or youtu.be/XXXXX]
    Check2 -->|No| Check3{FlashTalking?}
    
    Check3 -->|Yes| F1[Extract: flashtalking_account_base<br/>Pattern: cdn.flashtalking.com/account/filename<br/>Remove: _width_height_bitrate_fps]
    Check3 -->|No| Check4{FPT Play?}
    
    Check4 -->|Yes| FP1[Extract: fptplay_id<br/>Pattern: static/banner/date/id.mp4<br/>ID = part after underscore]
    Check4 -->|No| Check5{Adnxs?}
    
    Check5 -->|Yes| A1[Extract: adnxs_creative_uuid<br/>Pattern: creative_id/uuid]
    Check5 -->|No| Check6{VZ CDN?}
    
    Check6 -->|Yes| V1[Extract: vzcdn_uuid<br/>Pattern: vz-XXX.b-cdn.net/uuid/]
    Check6 -->|No| Check7{UpPremium?}
    
    Check7 -->|Yes| U1[Extract: upremium_filename<br/>Remove timestamp prefix]
    Check7 -->|No| Check8{BlueAdss?}
    
    Check8 -->|Yes| B1[Extract: blueadss_path_filename<br/>Combine path + filename]
    Check8 -->|No| Check9{Adsrvr?}
    
    Check9 -->|Yes| AD1[Extract: adsrvr_filename<br/>Pattern: v.adsrvr.org/.../filename]
    Check9 -->|No| Check10{AIActiv?}
    
    Check10 -->|Yes| AI1[Extract: aiactiv_base<br/>Remove numeric suffix]
    Check10 -->|No| Check11{FPT VOD?}
    
    Check11 -->|Yes| FV1[Extract: fptplay_vod_hash<br/>Pattern: vod/transcoded/HASH/]
    Check11 -->|No| Empty[Return: ""<br/>No Video ID found]
    
    G1 --> Return[Return Video ID]
    Y1 --> Return
    F1 --> Return
    FP1 --> Return
    A1 --> Return
    V1 --> Return
    U1 --> Return
    B1 --> Return
    AD1 --> Return
    AI1 --> Return
    FV1 --> Return
    Empty --> Return
```

---

## Resolution Extraction Patterns

```mermaid
flowchart TD
    URL[Input URL] --> Check1{Has itag?<br/>Google CDN}
    Check1 -->|Yes| I1[Map itag to resolution<br/>348â†’4K, 37â†’1080p, 22â†’720p, etc.]
    Check1 -->|No| Check2{Has pattern<br/>1920x1080 or 1920_1080?}
    
    Check2 -->|Yes| P1[Extract: width x height<br/>Validate: 100-7680 x 100-4320]
    Check2 -->|No| Check3{FlashTalking pattern?<br/>_width_height_bitrate_fps}
    
    Check3 -->|Yes| F1[Extract: width_height<br/>Pattern: _1920_1080_2500_3000]
    Check3 -->|No| Check4{Adnxs pattern?<br/>uuid_width_height_bitratek}
    
    Check4 -->|Yes| A1[Extract: width_height<br/>Pattern: uuid_1280_720_600k]
    Check4 -->|No| Check5{VZ CDN pattern?<br/>play_1080p}
    
    Check5 -->|Yes| V1[Map: play_1080p â†’ 1920x1080<br/>play_720p â†’ 1280x720<br/>Calculate 16:9 if needed]
    Check5 -->|No| Check6{Query params?<br/>?width=1920&height=1080}
    
    Check6 -->|Yes| Q1[Extract from params<br/>width & height or w & h]
    Check6 -->|No| Check7{Resolution keywords?<br/>1080p, 720p, 4k}
    
    Check7 -->|Yes| K1[Map keywords to resolution<br/>1080pâ†’1920x1080, 720pâ†’1280x720]
    Check7 -->|No| Zero[Return: 0, 0<br/>No resolution found]
    
    I1 --> Return[Return width, height]
    P1 --> Return
    F1 --> Return
    A1 --> Return
    V1 --> Return
    Q1 --> Return
    K1 --> Return
    Zero --> Return
```

---

## Pre-filtering Logic Flow

```mermaid
flowchart TD
    Start[Start Pre-filtering] --> Extract[Extract Video ID<br/>for each video]
    
    Extract --> Group[Group videos by Video ID<br/>video_id_groups]
    
    Group --> Stats[ğŸ“Š Statistics:<br/>- Videos with ID<br/>- Videos without ID<br/>- Unique video IDs]
    
    Stats --> CheckChunk{Chunk Mode?}
    
    CheckChunk -->|Yes| QueryOther[Query other chunks<br/>Batch query 5k/batch<br/>Find existing video IDs]
    CheckChunk -->|No| ProcessGroups
    
    QueryOther --> FindExisting[Find video IDs<br/>with smaller job_id<br/>in other chunks]
    
    FindExisting --> MarkSkip[Mark video_ids_to_skip<br/>Remove entire groups]
    
    MarkSkip --> ProcessGroups[Process each group]
    
    ProcessGroups --> CheckSkip{Video ID<br/>in skip list?}
    
    CheckSkip -->|Yes| RemoveAll[ğŸ—‘ï¸ Remove all videos<br/>in this group<br/>Already exists in other chunk]
    CheckSkip -->|No| CheckMultiple{Group has<br/>> 1 video?}
    
    CheckMultiple -->|No| KeepSingle[âœ… Keep single video<br/>No duplicates in group]
    CheckMultiple -->|Yes| ExtractRes[ğŸ“ Extract Resolution<br/>for each video in group]
    
    ExtractRes --> CalcScores["ğŸ“Š Calculate resolution_score<br/>for each video<br/>score = width x height"]
    
    CalcScores --> Sort[ğŸ”¢ Sort by:<br/>1. resolution_score DESC<br/>2. itag DESC<br/>3. job_id ASC]
    
    Sort --> SelectBest[âœ… Select best quality<br/>Highest resolution]
    
    SelectBest --> RemoveOthers[ğŸ—‘ï¸ Remove other videos<br/>in group]
    
    RemoveAll --> Summary
    KeepSingle --> Summary
    RemoveOthers --> Summary[ğŸ“Š Summary:<br/>- URL duplicates removed<br/>- Videos filtered]
    
    Summary --> End[End Pre-filtering]
```

---

## Clustering Logic Flow

```mermaid
flowchart TD
    Start[Start Clustering] --> BuildDict["ğŸ“š Build Similarity Dict<br/>job_id1, job_id2 to similarity<br/>Normalize: sort job_ids"]
    
    BuildDict --> BuildGraph["ğŸ•¸ï¸ Build Graph<br/>job_id to Set of neighbors<br/>Exclude cross-chunk duplicates"]
    
    BuildGraph --> InitDFS["ğŸ” Initialize DFS<br/>visited = set<br/>clusters = list"]
    
    InitDFS --> Iterate[Iterate through<br/>all job_ids<br/>Sorted by job_id number]
    
    Iterate --> CheckVisited{Already<br/>visited?}
    
    CheckVisited -->|Yes| Next[Next job_id]
    CheckVisited -->|No| StartDFS[Start DFS<br/>from this node]
    
    StartDFS --> DFSStack[DFS Stack:<br/>node, path, min_similarity]
    
    DFSStack --> CheckPath{Path length<br/>> max_path_length?<br/>default: 2}
    
    CheckPath -->|Yes| StopPath[â¹ï¸ Stop this path<br/>Too long]
    CheckPath -->|No| CheckSim{"Path similarity<br/>< threshold x 0.95?"}
    
    CheckSim -->|Yes| StopPath
    CheckSim -->|No| AddNode[âœ… Add node to cluster<br/>Mark as visited]
    
    AddNode --> GetNeighbors[Get neighbors<br/>from graph<br/>Sorted by job_id]
    
    GetNeighbors --> CheckNeighbor{Neighbor<br/>visited or in path?}
    
    CheckNeighbor -->|Yes| NextNeighbor[Next neighbor]
    CheckNeighbor -->|No| AddToStack[Add to DFS stack<br/>Update path & min_similarity]
    
    AddToStack --> DFSStack
    NextNeighbor --> CheckMore{More<br/>neighbors?}
    CheckMore -->|Yes| GetNeighbors
    CheckMore -->|No| CheckStack{Stack<br/>empty?}
    
    CheckStack -->|No| DFSStack
    CheckStack -->|Yes| SaveCluster[ğŸ’¾ Save cluster<br/>Add to clusters list]
    
    StopPath --> CheckStack
    SaveCluster --> Next
    Next --> CheckMoreNodes{More<br/>job_ids?}
    
    CheckMoreNodes -->|Yes| Iterate
    CheckMoreNodes -->|No| End[âœ… End Clustering<br/>Return clusters]
```

---

## Best Quality Selection Logic

```mermaid
flowchart TD
    Start[Videos in group/cluster] --> ExtractRes[ğŸ“ Extract Resolution<br/>for each video]
    
    ExtractRes --> CheckRes{Resolution<br/>found?}
    
    CheckRes -->|Yes| CalcScore["ğŸ“Š Calculate score<br/>resolution_score = width x height<br/>Example: 1920x1080 = 2,073,600"]
    CheckRes -->|No| CheckItag{Has itag?}
    
    CheckItag -->|Yes| UseItag[Use itag as score<br/>Higher itag = better quality]
    CheckItag -->|No| ScoreZero[Score = 0<br/>No quality info]
    
    CalcScore --> Sort[ğŸ”¢ Sort videos by:<br/>1. resolution_score DESC<br/>2. itag DESC<br/>3. job_id ASC]
    
    UseItag --> Sort
    ScoreZero --> Sort
    
    Sort --> Select[âœ… Select first video<br/>Highest resolution<br/>or smallest job_id]
    
    Select --> Log[ğŸ“ Log selection:<br/>- Resolution info<br/>- Score<br/>- Reason]
    
    Log --> End[Return best video]
```

---

## Key Improvements Summary

### 1. Video ID Extraction (8 CDN má»›i)
- **FlashTalking**: `flashtalking_{account_id}_{base_filename}`
- **FPT Play**: `fptplay_{id}` hoáº·c `fptplay_vod_{hash}`
- **Adnxs**: `adnxs_{creative_id}_{uuid}`
- **VZ CDN**: `vzcdn_{uuid}`
- **UpPremium**: `upremium_{base_filename}`
- **BlueAdss**: `blueadss_{path}_{filename}`
- **Adsrvr**: `adsrvr_{filename}`
- **AIActiv**: `aiactiv_{base_filename}`

### 2. Resolution Extraction (4 patterns má»›i)
- **FlashTalking**: `_width_height_bitrate_fps.mp4`
- **Adnxs**: `uuid_width_height_bitratek.ext`
- **VZ CDN**: `play_1080p.mp4` â†’ map to 1920x1080
- **Query params**: `?width=1920&height=1080`

### 3. Best Quality Selection
- **DÃ¹ng resolution_score** (width Ã— height) thay vÃ¬ chá»‰ itag
- **Sort order**: resolution_score DESC â†’ itag DESC â†’ job_id ASC
- **Äáº£m báº£o** chá»n video cÃ³ resolution cao nháº¥t

### 4. Cross-chunk Detection
- **Threshold riÃªng**: `cross_chunk_threshold` (default: 0.98)
- **Batch querying**: Query 5k videos/batch Ä‘á»ƒ tá»‘i Æ°u
- **Chá»‰ mark duplicate** náº¿u original á»Ÿ chunk khÃ¡c

### 5. Path Validation trong DFS
- **Max path length**: 2 (trÃ¡nh transitive closure)
- **Path similarity**: >= threshold Ã— 0.95
- **Prevent**: A-B-C-D where A and D are not similar

---

## Performance Optimizations

1. **Batch Querying**: Query 100 videos/batch Ä‘á»ƒ trÃ¡nh message size limit
2. **Parallel Processing**: num_threads threads cho batch search
3. **Similarity Lookup Dict**: O(1) lookup thay vÃ¬ O(n) search
4. **Memory Cleanup**: Clear all_data sau khi khÃ´ng cáº§n
5. **Deterministic Sorting**: Sort by job_id number Ä‘á»ƒ Ä‘áº£m báº£o káº¿t quáº£ nháº¥t quÃ¡n

---

## Output Files

1. **unique_csv**: Danh sÃ¡ch URLs unique (decoded_url)
2. **report_csv**: Duplicates report vá»›i mapping (duplicate_url, original_url, similarity)
3. **invalid_csv**: Invalid URLs report (náº¿u --auto_clean, gá»“m url, job_id, reason)

---

## Command Line Options

- `--skip_url_dedup`: Táº¯t pre-filtering (giá»¯ táº¥t cáº£ videos)
- `--skip_cross_chunk`: Táº¯t cross-chunk duplicate removal
- `--cross_chunk_threshold`: Threshold cho cross-chunk (default: 0.98)
- `--auto_clean`: Tá»± Ä‘á»™ng loáº¡i bá» invalid URLs
- `--fast_mode`: DÃ¹ng search params tá»‘i Æ°u (nhanh hÆ¡n 2-4x)
- `--batch_size`: Batch size cho search (max 10)
- `--num_threads`: Sá»‘ threads cho parallel search
