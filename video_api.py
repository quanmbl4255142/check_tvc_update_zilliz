"""
Flask API endpoint ƒë·ªÉ nh·∫≠n video URL v√† g·ª≠i v√†o Kafka
Endpoint: POST /api/video
"""

import os
import json
import uuid
import time
import threading
import queue
import redis
from datetime import datetime
from flask import Flask, request, jsonify
from kafka import KafkaProducer
from kafka.admin import KafkaAdminClient, NewTopic
from kafka.errors import TopicAlreadyExistsError
from rich.console import Console

console = Console()

app = Flask(__name__)

# Kafka configuration
# D√πng 127.0.0.1 thay v√¨ localhost ƒë·ªÉ tr√°nh v·∫•n ƒë·ªÅ DNS resolution
KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "127.0.0.1:9092")
KAFKA_TOPIC = os.getenv("KAFKA_TOPIC", "video_processing")

# Redis configuration
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
REDIS_DB = int(os.getenv("REDIS_DB", "0"))

# Kafka timeout configuration - Import t·ª´ timeout_config
try:
    from timeout_config import (
        KAFKA_WAIT_READY_TIMEOUT,
        KAFKA_REQUEST_TIMEOUT_MS,
        KAFKA_MAX_BLOCK_MS,
        KAFKA_SEND_TIMEOUT_MS,
        KAFKA_RETRIES,
        KAFKA_RETRY_DELAY,
        REDIS_SOCKET_CONNECT_TIMEOUT,
        REDIS_SOCKET_TIMEOUT,
        REDIS_HEALTH_CHECK_INTERVAL,
        REDIS_CONNECTION_RETRIES,
        REDIS_RETRY_DELAY,
        RESULT_WAIT_TIMEOUT,
        RESULT_POLL_INTERVAL,
    )
except ImportError:
    # Fallback n·∫øu kh√¥ng c√≥ timeout_config
    KAFKA_WAIT_READY_TIMEOUT = int(os.getenv("KAFKA_WAIT_READY_TIMEOUT", "15"))
    KAFKA_REQUEST_TIMEOUT_MS = int(os.getenv("KAFKA_REQUEST_TIMEOUT_MS", "10000"))
    KAFKA_MAX_BLOCK_MS = int(os.getenv("KAFKA_MAX_BLOCK_MS", "10000"))
    KAFKA_SEND_TIMEOUT_MS = int(os.getenv("KAFKA_SEND_TIMEOUT_MS", "10000"))
    KAFKA_RETRIES = int(os.getenv("KAFKA_RETRIES", "3"))
    KAFKA_RETRY_DELAY = int(os.getenv("KAFKA_RETRY_DELAY", "2"))
    REDIS_SOCKET_CONNECT_TIMEOUT = int(os.getenv("REDIS_SOCKET_CONNECT_TIMEOUT", "5"))
    REDIS_SOCKET_TIMEOUT = int(os.getenv("REDIS_SOCKET_TIMEOUT", "5"))
    REDIS_HEALTH_CHECK_INTERVAL = int(os.getenv("REDIS_HEALTH_CHECK_INTERVAL", "30"))
    REDIS_CONNECTION_RETRIES = int(os.getenv("REDIS_CONNECTION_RETRIES", "5"))
    REDIS_RETRY_DELAY = float(os.getenv("REDIS_RETRY_DELAY", "2"))
    RESULT_WAIT_TIMEOUT = int(os.getenv("RESULT_WAIT_TIMEOUT", "30"))
    RESULT_POLL_INTERVAL = float(os.getenv("RESULT_POLL_INTERVAL", "0.5"))

# Initialize Kafka producer
producer = None

def ensure_topic_exists():
    """ƒê·∫£m b·∫£o topic t·ªìn t·∫°i - t·∫°o topic b·∫±ng AdminClient v·ªõi retry mechanism"""
    from kafka.admin import KafkaAdminClient, NewTopic
    from kafka.errors import TopicAlreadyExistsError, NodeNotReadyError
    
    max_retries = 5
    retry_delay = 3
    
    for attempt in range(max_retries):
        try:
            # Th·ª≠ t·∫°o topic b·∫±ng AdminClient
            admin_client = KafkaAdminClient(
                bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
                client_id=f'video_api_admin_{attempt}',
                request_timeout_ms=min(KAFKA_REQUEST_TIMEOUT_MS, 20000),  # Max 20s
                api_version=(0, 10, 1)
            )
            
            # ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ AdminClient kh·ªüi t·∫°o (gi·∫£m delay ƒë·ªÉ nhanh h∆°n)
            if attempt > 0:
                time.sleep(min(retry_delay, 2))  # Max 2s delay
            
            # Ki·ªÉm tra topic c√≥ t·ªìn t·∫°i kh√¥ng
            try:
                topics = admin_client.list_topics()
                topic_list = list(topics) if isinstance(topics, (set, list)) else topics
                
                if KAFKA_TOPIC in topic_list:
                    console.print(f"[green]‚úÖ Topic {KAFKA_TOPIC} already exists[/green]")
                    admin_client.close()
                    return True
            except (NodeNotReadyError, Exception) as list_error:
                if isinstance(list_error, NodeNotReadyError) and attempt < max_retries - 1:
                    console.print(f"[yellow]‚ö†Ô∏è  Kafka not ready yet (attempt {attempt + 1}/{max_retries}): {list_error}[/yellow]")
                    admin_client.close()
                    time.sleep(retry_delay)
                    continue
                console.print(f"[dim]Could not list topics: {list_error}[/dim]")
                # Continue to try creating topic
            
            # T·∫°o topic n·∫øu ch∆∞a t·ªìn t·∫°i
            console.print(f"[cyan]Creating topic {KAFKA_TOPIC} (attempt {attempt + 1}/{max_retries})...[/cyan]")
            topic = NewTopic(
                name=KAFKA_TOPIC,
                num_partitions=1,
                replication_factor=1
            )
            
            try:
                admin_client.create_topics([topic], timeout_ms=20000)
                console.print(f"[green]‚úÖ Topic {KAFKA_TOPIC} created successfully[/green]")
                # ƒê·ª£i topic ƒë∆∞·ª£c t·∫°o xong v√† metadata ƒë∆∞·ª£c sync
                console.print(f"[dim]Waiting for topic metadata to sync (2 seconds)...[/dim]")
                time.sleep(2)
                admin_client.close()
                return True
            except TopicAlreadyExistsError:
                console.print(f"[green]‚úÖ Topic {KAFKA_TOPIC} already exists[/green]")
                admin_client.close()
                return True
            except (NodeNotReadyError, Exception) as create_error:
                if isinstance(create_error, NodeNotReadyError) and attempt < max_retries - 1:
                    console.print(f"[yellow]‚ö†Ô∏è  Kafka not ready yet (attempt {attempt + 1}/{max_retries}): {create_error}[/yellow]")
                    admin_client.close()
                    time.sleep(retry_delay)
                    continue
                console.print(f"[yellow]‚ö†Ô∏è  Could not create topic: {create_error}[/yellow]")
                admin_client.close()
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                return False
            
        except (NodeNotReadyError, Exception) as e:
            if isinstance(e, NodeNotReadyError) and attempt < max_retries - 1:
                console.print(f"[yellow]‚ö†Ô∏è  AdminClient error (attempt {attempt + 1}/{max_retries}): {e}[/yellow]")
                console.print(f"[dim]   Retrying in {retry_delay} seconds...[/dim]")
                time.sleep(retry_delay)
                continue
            console.print(f"[yellow]‚ö†Ô∏è  AdminClient error: {e}[/yellow]")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                continue
            console.print(f"[dim]   Topic will be auto-created on first message[/dim]")
            return False
    
    console.print(f"[yellow]‚ö†Ô∏è  Could not create topic after {max_retries} attempts[/yellow]")
    console.print(f"[dim]   Topic will be auto-created on first message[/dim]")
    return False

def get_redis_client():
    """Lazy initialization of Redis client v·ªõi retry v√† connection pooling"""
    max_retries = REDIS_CONNECTION_RETRIES
    retry_delay = REDIS_RETRY_DELAY
    
    for attempt in range(max_retries):
        try:
            return redis.Redis(
                host=REDIS_HOST,
                port=REDIS_PORT,
                db=REDIS_DB,
                decode_responses=True,
                socket_connect_timeout=REDIS_SOCKET_CONNECT_TIMEOUT,
                socket_timeout=REDIS_SOCKET_TIMEOUT,
                socket_keepalive=True,
                health_check_interval=REDIS_HEALTH_CHECK_INTERVAL,
                # Removed deprecated retry_on_timeout and retry_on_error (included by default in redis-py 6.0+)
            )
        except (redis.ConnectionError, redis.TimeoutError) as e:
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                retry_delay *= 1.5
            else:
                console.print(f"[yellow]‚ö†Ô∏è  Redis connection error after {max_retries} attempts: {e}[/yellow]")
                return None
        except Exception as e:
            console.print(f"[yellow]‚ö†Ô∏è  Redis connection error: {e}[/yellow]")
            return None

def wait_for_result(request_id: str, timeout: int, poll_interval: float):
    """
    ƒê·ª£i k·∫øt qu·∫£ t·ª´ consumer trong Redis
    
    Args:
        request_id: Request ID ƒë·ªÉ query
        timeout: Timeout t·ªëi ƒëa (gi√¢y)
        poll_interval: Kho·∫£ng th·ªùi gian gi·ªØa c√°c l·∫ßn poll (gi√¢y)
    
    Returns:
        dict: K·∫øt qu·∫£ t·ª´ consumer ho·∫∑c None n·∫øu timeout
    """
    redis_client = get_redis_client()
    if not redis_client:
        return None
    
    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            result_key = f"request_id:{request_id}"
            result_json = redis_client.get(result_key)
            
            if result_json:
                result = json.loads(result_json)
                # Chuy·ªÉn ƒë·ªïi response format ƒë·ªÉ ph√π h·ª£p v·ªõi API
                return {
                    "status": "success" if result.get("status") == "completed" else result.get("status"),
                    "message": result.get("message", ""),
                    "request_id": result.get("request_id", request_id),
                    "video_url": result.get("video_url", ""),
                    "unique_id": result.get("unique_id"),
                    "is_new": result.get("is_new", False),
                    "similarity": result.get("similarity", 0.0),
                    "added_at": result.get("added_at"),
                    "cache_hit": result.get("cache_hit", False),
                    "stats_before": result.get("stats_before"),
                    "stats_after": result.get("stats_after")
                }
        except Exception as e:
            console.print(f"[yellow]‚ö†Ô∏è  Error polling Redis: {e}[/yellow]")
        
        time.sleep(poll_interval)
    
    return None

# Cache ƒë·ªÉ tr√°nh check Kafka ready nhi·ªÅu l·∫ßn
_kafka_ready_cache = {"ready": False, "last_check": 0, "cache_ttl": 30}

def check_kafka_socket(host='localhost', port=9092, timeout=2):
    """Ki·ªÉm tra Kafka socket c√≥ s·∫µn s√†ng kh√¥ng (nhanh h∆°n AdminClient)"""
    import socket
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, port))
        sock.close()
        return result == 0
    except:
        return False

def wait_for_kafka_ready(max_wait=None, force_check=False):
    """ƒê·ª£i Kafka broker s·∫µn s√†ng - test b·∫±ng socket check v√† AdminClient"""
    from kafka.admin import KafkaAdminClient
    from kafka.errors import KafkaError
    import socket
    
    # S·ª≠ d·ª•ng timeout t·ª´ config n·∫øu kh√¥ng ch·ªâ ƒë·ªãnh
    if max_wait is None:
        max_wait = KAFKA_WAIT_READY_TIMEOUT
    
    # S·ª≠ d·ª•ng cache n·∫øu ƒë√£ check g·∫ßn ƒë√¢y
    current_time = time.time()
    if not force_check and _kafka_ready_cache["ready"]:
        if current_time - _kafka_ready_cache["last_check"] < _kafka_ready_cache["cache_ttl"]:
            return True
    
    # Parse bootstrap servers ƒë·ªÉ l·∫•y host v√† port
    bootstrap_host = "localhost"
    bootstrap_port = 9092
    try:
        if ":" in KAFKA_BOOTSTRAP_SERVERS:
            parts = KAFKA_BOOTSTRAP_SERVERS.split(":")
            bootstrap_host = parts[0].replace("localhost", "127.0.0.1")
            bootstrap_port = int(parts[1])
        else:
            bootstrap_host = KAFKA_BOOTSTRAP_SERVERS.replace("localhost", "127.0.0.1")
    except:
        pass
    
    start_time = time.time()
    attempt = 0
    
    # B∆∞·ªõc 1: Ki·ªÉm tra socket tr∆∞·ªõc (nhanh h∆°n)
    console.print(f"[dim]Checking Kafka socket at {bootstrap_host}:{bootstrap_port}...[/dim]")
    socket_ready = False
    socket_check_timeout = min(max_wait, 10)  # Max 10s ƒë·ªÉ check socket
    socket_start_time = time.time()
    
    while time.time() - socket_start_time < socket_check_timeout and not socket_ready:
        socket_ready = check_kafka_socket(bootstrap_host, bootstrap_port, timeout=2)
        if socket_ready:
            console.print(f"[green]‚úÖ Kafka socket is open[/green]")
            # ƒê·ª£i 5-7 gi√¢y ƒë·ªÉ Kafka ho√†n to√†n s·∫µn s√†ng (Zookeeper connection, metadata init)
            # Gi·∫£m t·ª´ 10s xu·ªëng 5s ƒë·ªÉ nhanh h∆°n
            console.print(f"[dim]Waiting for Kafka broker to fully initialize (5 seconds)...[/dim]")
            time.sleep(5)  # ƒê·ª£i 5s ƒë·ªÉ Kafka kh·ªüi t·∫°o metadata v√† s·∫µn s√†ng nh·∫≠n requests
            break
        time.sleep(1)
    
    if not socket_ready:
        console.print(f"[red]‚ùå Kafka socket is not open at {bootstrap_host}:{bootstrap_port}[/red]")
        console.print(f"[yellow]üí° H√£y ki·ªÉm tra Kafka ƒëang ch·∫°y: docker ps | findstr kafka[/yellow]")
        console.print(f"[yellow]üí° Ho·∫∑c kh·ªüi ƒë·ªông Kafka: docker-compose up -d[/yellow]")
        _kafka_ready_cache["ready"] = False
        _kafka_ready_cache["last_check"] = time.time()
        return False
    
    # B∆∞·ªõc 2: Test b·∫±ng Producer thay v√¨ AdminClient (reliable h∆°n)
    # Producer c√≥ th·ªÉ k·∫øt n·ªëi ngay c·∫£ khi AdminClient fail
    attempt = 0
    producer_check_start = time.time()
    remaining_time = max_wait - (time.time() - start_time)
    
    # ƒê·∫£m b·∫£o c√≤n √≠t nh·∫•t 10s ƒë·ªÉ test Producer
    if remaining_time < 10:
        console.print(f"[yellow]‚ö†Ô∏è  Kh√¥ng ƒë·ªß th·ªùi gian ƒë·ªÉ test Producer (c√≤n {remaining_time:.1f}s)[/yellow]")
        console.print(f"[yellow]üí° Kafka socket m·ªü nh∆∞ng broker c√≥ th·ªÉ ch∆∞a s·∫µn s√†ng. S·∫Ω th·ª≠ t·∫°o Producer tr·ª±c ti·∫øp.[/yellow]")
        _kafka_ready_cache["ready"] = False
        _kafka_ready_cache["last_check"] = time.time()
        return False  # Nh∆∞ng v·∫´n cho ph√©p t·∫°o Producer
    
    while time.time() - producer_check_start < remaining_time:
        try:
            attempt += 1
            console.print(f"[dim]Testing Kafka broker readiness with Producer (attempt {attempt})...[/dim]")
            
            # Test b·∫±ng c√°ch t·∫°o Producer v√† th·ª≠ fetch metadata
            # Producer th∆∞·ªùng reliable h∆°n AdminClient
            test_producer = KafkaProducer(
                bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
                request_timeout_ms=min(KAFKA_REQUEST_TIMEOUT_MS, 15000),
                max_block_ms=min(KAFKA_MAX_BLOCK_MS, 15000),
                api_version=(0, 10, 1)
            )
            
            # ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ Producer kh·ªüi t·∫°o
            time.sleep(1)
            
            # Th·ª≠ fetch metadata b·∫±ng c√°ch g·ªçi partitions_for (non-blocking n·∫øu metadata ƒë√£ c√≥)
            # Ho·∫∑c th·ª≠ send m·ªôt dummy message v·ªõi timeout ng·∫Øn
            try:
                partitions = test_producer.partitions_for(KAFKA_TOPIC)
                if partitions is not None:
                    console.print(f"[dim]   Metadata available: {len(partitions) if partitions else 0} partition(s)[/dim]")
            except:
                # Metadata ch∆∞a c√≥, nh∆∞ng Producer ƒë√£ t·∫°o ƒë∆∞·ª£c - c√≥ nghƒ©a l√† Kafka s·∫µn s√†ng
                pass
            
            test_producer.close(timeout=2)
            
            # Update cache
            _kafka_ready_cache["ready"] = True
            _kafka_ready_cache["last_check"] = time.time()
            total_time = time.time() - start_time
            console.print(f"[green]‚úÖ Kafka broker is ready! (after {attempt} attempt(s), {total_time:.1f}s)[/green]")
            return True
        except (KafkaError, Exception) as e:
            # Ch∆∞a s·∫µn s√†ng, ƒë·ª£i th√™m
            elapsed = time.time() - producer_check_start
            remaining = remaining_time - elapsed
            if remaining > 5:  # C√≤n √≠t nh·∫•t 5s th√¨ retry
                wait_time = min(3, remaining / 2)  # ƒê·ª£i 3s ho·∫∑c m·ªôt n·ª≠a th·ªùi gian c√≤n l·∫°i
                error_msg = str(e)[:100]
                console.print(f"[yellow]‚ö†Ô∏è  Broker not ready yet (attempt {attempt}): {error_msg}[/yellow]")
                console.print(f"[dim]   Waiting {wait_time:.1f}s before retry...[/dim]")
                time.sleep(wait_time)
            else:
                # Kh√¥ng c√≤n th·ªùi gian ƒë·ªÉ retry
                break
    
    # Update cache - kh√¥ng ready
    _kafka_ready_cache["ready"] = False
    _kafka_ready_cache["last_check"] = time.time()
    console.print(f"[yellow]‚ö†Ô∏è  Kafka socket is open but broker may not be fully ready after {max_wait}s[/yellow]")
    console.print(f"[yellow]üí° Kafka c√≥ th·ªÉ ƒëang kh·ªüi ƒë·ªông ho·∫∑c c√≥ v·∫•n ƒë·ªÅ. H√£y th·ª≠:[/yellow]")
    console.print(f"[yellow]   1. Ki·ªÉm tra Kafka logs: docker logs kafka[/yellow]")
    console.print(f"[yellow]   2. Ki·ªÉm tra Zookeeper: docker logs zookeeper[/yellow]")
    console.print(f"[yellow]   3. Restart Kafka: docker restart kafka[/yellow]")
    console.print(f"[yellow]   4. ƒê·ª£i 30-60 gi√¢y r·ªìi th·ª≠ l·∫°i[/yellow]")
    return False

def get_kafka_producer():
    """Lazy initialization of Kafka producer - ƒê∆†N GI·∫¢N H√ìA v·ªõi pre-fetch metadata"""
    global producer
    if producer is None:
        try:
            # T·∫°o producer v·ªõi timeout d√†i h∆°n ƒë·ªÉ fetch metadata
            producer = KafkaProducer(
                bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                key_serializer=lambda k: k.encode('utf-8') if k else None,
                acks=1,  # ƒê·ªïi sang acks=1 ƒë·ªÉ ƒë·∫£m b·∫£o message ƒë∆∞·ª£c g·ª≠i (v·∫´n nhanh)
                retries=3,
                max_in_flight_requests_per_connection=1,
                request_timeout_ms=30000,  # 30s - tƒÉng ƒë·ªÉ ƒë·ªß cho request ƒë·∫øn partition leader
                metadata_max_age_ms=300000,  # 5 ph√∫t
                connections_max_idle_ms=540000,  # 9 ph√∫t
                linger_ms=0,
                batch_size=0,
                max_block_ms=60000,  # 60s - tƒÉng ƒë·ªÉ ƒë·ªß fetch metadata v√† k·∫øt n·ªëi ƒë·∫øn partition leader
                api_version=(0, 10, 1)
            )
            
            # Pre-fetch metadata ngay khi t·∫°o producer
            console.print(f"[dim]Pre-fetching metadata for topic {KAFKA_TOPIC}...[/dim]")
            metadata_ready = False
            for meta_attempt in range(3):
                try:
                    partitions = producer.partitions_for(KAFKA_TOPIC)
                    if partitions:
                        console.print(f"[green]‚úÖ Metadata ready: {len(partitions)} partition(s)[/green]")
                        metadata_ready = True
                        break
                    else:
                        if meta_attempt < 2:
                            console.print(f"[dim]   Metadata ch∆∞a c√≥, ƒë·ª£i 2s r·ªìi th·ª≠ l·∫°i...[/dim]")
                            time.sleep(2)
                        else:
                            console.print(f"[yellow]‚ö†Ô∏è  Topic metadata not available yet, will fetch on first send[/yellow]")
                except Exception as meta_error:
                    if meta_attempt < 2:
                        console.print(f"[dim]   Metadata fetch failed, ƒë·ª£i 2s r·ªìi th·ª≠ l·∫°i: {meta_error}[/dim]")
                        time.sleep(2)
                    else:
                        console.print(f"[yellow]‚ö†Ô∏è  Could not pre-fetch metadata: {meta_error}[/yellow]")
                        console.print(f"[dim]   Will fetch on first send (max_block: 30s)[/dim]")
            
            console.print(f"[green]‚úÖ Kafka producer created (ƒë∆°n gi·∫£n h√≥a)[/green]")
        except Exception as e:
            console.print(f"[red]‚ùå Failed to create Kafka producer: {e}[/red]")
            raise
    return producer


@app.route('/api/video', methods=['POST'])
def add_video():
    """
    Nh·∫≠n video URL v√† g·ª≠i v√†o Kafka
    
    Request body:
    {
        "video_url": "https://example.com/video.mp4"
    }
    
    Response:
    {
        "status": "success",
        "message": "Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o Kafka",
        "request_id": "uuid",
        "video_url": "https://example.com/video.mp4",
        "timestamp": "2024-01-01T00:00:00"
    }
    """
    try:
        data = request.get_json()
        
        if not data or 'video_url' not in data:
            return jsonify({
                "status": "error",
                "message": "Thi·∫øu video_url trong request body"
            }), 400
        
        video_url = data['video_url'].strip()
        
        if not video_url:
            return jsonify({
                "status": "error",
                "message": "video_url kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
            }), 400
        
        # URL validation - ki·ªÉm tra format URL h·ª£p l·ªá
        import re
        from urllib.parse import urlparse
        
        # Basic URL validation
        url_pattern = re.compile(
            r'^https?://'  # http:// or https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        
        if not url_pattern.match(video_url):
            return jsonify({
                "status": "error",
                "message": "video_url kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng URL h·ª£p l·ªá"
            }), 400
        
        # Parse URL ƒë·ªÉ ki·ªÉm tra scheme v√† host
        try:
            parsed = urlparse(video_url)
            if not parsed.scheme or not parsed.netloc:
                return jsonify({
                    "status": "error",
                    "message": "video_url ph·∫£i c√≥ scheme (http/https) v√† host"
                }), 400
        except Exception as e:
            return jsonify({
                "status": "error",
                "message": f"video_url kh√¥ng h·ª£p l·ªá: {str(e)}"
            }), 400
        
        # Generate unique request ID
        request_id = str(uuid.uuid4())
        timestamp = datetime.now().isoformat()
        
        # Create message payload
        message = {
            "request_id": request_id,
            "video_url": video_url,
            "timestamp": timestamp,
            "status": "pending"
        }
        
        # Send to Kafka - Fire and forget (kh√¥ng ƒë·ª£i confirmation ƒë·ªÉ tr√°nh timeout)
        try:
            console.print(f"[cyan]üì§ Sending video to Kafka: {video_url[:60]}...[/cyan]")
            console.print(f"[dim]Request ID: {request_id}[/dim]")
            
            # Th·ª≠ l·∫•y producer (c√≥ th·ªÉ fail n·∫øu Kafka ch∆∞a s·∫µn s√†ng)
            try:
                kafka_producer = get_kafka_producer()
            except Exception as producer_error:
                # N·∫øu kh√¥ng t·∫°o ƒë∆∞·ª£c producer, v·∫´n tr·∫£ v·ªÅ "processing"
                console.print(f"[yellow]‚ö†Ô∏è  Kh√¥ng th·ªÉ t·∫°o Kafka producer: {producer_error}[/yellow]")
                console.print(f"[dim]   Tr·∫£ v·ªÅ status 'processing' - UI s·∫Ω poll status endpoint[/dim]")
                return jsonify({
                    "status": "processing",
                    "message": "Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o h√†ng ƒë·ª£i, ƒëang ch·ªù Kafka s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra l·∫°i sau.",
                    "request_id": request_id,
                    "video_url": video_url,
                    "timestamp": timestamp,
                    "kafka_status": "not_ready",
                    "check_status_url": f"/api/video/status/{request_id}"
                }), 202
            
            # G·ª≠i message - v·ªõi acks=0, Producer s·∫Ω kh√¥ng block v√† tr·∫£ v·ªÅ ngay
            # Nh∆∞ng v·∫´n c·∫ßn fetch metadata tr∆∞·ªõc khi g·ª≠i
            console.print(f"[cyan]üì§ Sending message to Kafka topic: {KAFKA_TOPIC}...[/cyan]")
            console.print(f"[dim]   Request ID: {request_id}[/dim]")
            
            # ƒê∆†N GI·∫¢N H√ìA: G·ª≠i message tr·ª±c ti·∫øp v·ªõi retry
            # Metadata ƒë√£ ƒë∆∞·ª£c pre-fetch khi t·∫°o producer, nh∆∞ng c√≥ th·ªÉ c·∫ßn retry
            max_send_attempts = 3
            send_retry_delay = 2
            last_error = None
            
            for send_attempt in range(max_send_attempts):
                try:
                    if send_attempt > 0:
                        console.print(f"[dim]Retry attempt {send_attempt + 1}/{max_send_attempts}...[/dim]")
                        time.sleep(send_retry_delay)
                    
                    console.print(f"[cyan]üì§ G·ª≠i message tr·ª±c ti·∫øp v√†o Kafka...[/cyan]")
                    future = kafka_producer.send(
                        KAFKA_TOPIC,
                        value=message,
                        key=request_id
                    )
                    
                    # ƒê·ª£i x√°c nh·∫≠n v·ªõi timeout 30s - ƒë·ªß ƒë·ªÉ k·∫øt n·ªëi ƒë·∫øn partition leader
                    # V·ªõi acks=1, s·∫Ω ƒë·ª£i leader acknowledgment
                    # TƒÉng timeout v√¨ c√≥ th·ªÉ c·∫ßn th·ªùi gian ƒë·ªÉ k·∫øt n·ªëi ƒë·∫øn partition leader
                    record_metadata = future.get(timeout=30)
                    console.print(f"[green]‚úÖ Message ƒë√£ ƒë∆∞·ª£c g·ª≠i th√†nh c√¥ng! Partition: {record_metadata.partition}, Offset: {record_metadata.offset}[/green]")
                    
                    # Th√†nh c√¥ng - return ngay
                    return jsonify({
                        "status": "processing",
                        "message": "Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o Kafka v√† ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω",
                        "request_id": request_id,
                        "video_url": video_url,
                        "timestamp": timestamp,
                        "kafka_topic": KAFKA_TOPIC,
                        "partition": record_metadata.partition,
                        "offset": record_metadata.offset,
                        "check_status_url": f"/api/video/status/{request_id}",
                        "note": "ƒê·∫£m b·∫£o video_consumer.py ƒëang ch·∫°y ƒë·ªÉ x·ª≠ l√Ω message."
                    }), 202
                    
                except Exception as send_error:
                    last_error = send_error
                    error_str = str(send_error).lower()
                    
                    # N·∫øu l√† metadata timeout v√† c√≤n retry, th·ª≠ l·∫°i
                    if ("metadata" in error_str or "timeout" in error_str) and send_attempt < max_send_attempts - 1:
                        console.print(f"[yellow]‚ö†Ô∏è  Metadata timeout (attempt {send_attempt + 1}/{max_send_attempts}): {send_error}[/yellow]")
                        console.print(f"[dim]   Retrying in {send_retry_delay} seconds...[/dim]")
                        continue
                    
                    # N·∫øu ƒë√£ retry h·∫øt, break ƒë·ªÉ x·ª≠ l√Ω l·ªói b√™n ngo√†i
                    if send_attempt == max_send_attempts - 1:
                        break
            
            # X·ª≠ l√Ω l·ªói sau khi retry h·∫øt
            if last_error:
                error_str = str(last_error).lower()
                console.print(f"[red]‚ùå Error sending to Kafka after {max_send_attempts} attempts: {last_error}[/red]")
                
                # N·∫øu l√† metadata timeout, v·∫´n tr·∫£ v·ªÅ processing (c√≥ th·ªÉ retry)
                if "metadata" in error_str or "timeout" in error_str:
                    console.print(f"[yellow]‚ö†Ô∏è  Metadata timeout, nh∆∞ng s·∫Ω retry trong background[/yellow]")
                    return jsonify({
                        "status": "processing",
                        "message": "Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o h√†ng ƒë·ª£i. Kafka ƒëang fetch metadata, message s·∫Ω ƒë∆∞·ª£c g·ª≠i trong background.",
                        "request_id": request_id,
                        "video_url": video_url,
                        "timestamp": timestamp,
                        "kafka_status": "metadata_fetching",
                        "kafka_error": str(last_error),
                        "check_status_url": f"/api/video/status/{request_id}",
                        "note": "Producer s·∫Ω retry t·ª± ƒë·ªông. Vui l√≤ng ƒë·ª£i v√† ki·ªÉm tra l·∫°i sau."
                    }), 202
                else:
                    # L·ªói kh√°c
                    return jsonify({
                        "status": "error",
                        "message": f"Kh√¥ng th·ªÉ g·ª≠i message v√†o Kafka: {str(last_error)}",
                        "request_id": request_id,
                        "video_url": video_url,
                        "timestamp": timestamp,
                        "kafka_error": str(last_error),
                        "hint": "Ki·ªÉm tra Kafka ƒëang ch·∫°y: docker ps | findstr kafka"
                    }), 500
            
        except Exception as e:
            error_str = str(e).lower()
            console.print(f"[red]‚ùå Failed to send to Kafka: {e}[/red]")
            import traceback
            traceback.print_exc()
            
            # N·∫øu l√† connection/metadata error, tr·∫£ v·ªÅ processing ƒë·ªÉ UI c√≥ th·ªÉ retry
            if "metadata" in error_str or "timeout" in error_str or "node" in error_str or "connection" in error_str:
                console.print(f"[yellow]üí° Kafka kh√¥ng s·∫µn s√†ng. Tr·∫£ v·ªÅ processing ƒë·ªÉ UI c√≥ th·ªÉ retry sau.[/yellow]")
                return jsonify({
                    "status": "processing",
                    "message": "Kafka broker ch∆∞a s·∫µn s√†ng. Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o h√†ng ƒë·ª£i, ƒëang ch·ªù Kafka. Vui l√≤ng ki·ªÉm tra Kafka v√† th·ª≠ l·∫°i sau.",
                    "request_id": request_id,
                    "video_url": video_url,
                    "timestamp": timestamp,
                    "kafka_status": "not_ready",
                    "kafka_error": str(e),
                    "check_status_url": f"/api/video/status/{request_id}",
                    "troubleshooting": [
                        "1. Ki·ªÉm tra Kafka: docker ps | findstr kafka",
                        "2. Kh·ªüi ƒë·ªông Kafka: docker-compose up -d",
                        "3. ƒê·ª£i 30-60 gi√¢y ƒë·ªÉ Kafka kh·ªüi ƒë·ªông",
                        "4. Ki·ªÉm tra logs: docker logs kafka"
                    ]
                }), 202
            else:
                # L·ªói kh√°c
                return jsonify({
                    "status": "error",
                    "message": f"L·ªói khi g·ª≠i v√†o Kafka: {str(e)}",
                    "request_id": request_id,
                    "video_url": video_url,
                    "timestamp": timestamp,
                    "kafka_error": str(e),
                    "hint": "Ki·ªÉm tra Kafka ƒëang ch·∫°y: docker ps | findstr kafka"
                }), 500
            
    except Exception as e:
        console.print(f"[red]‚ùå API Error: {e}[/red]")
        return jsonify({
            "status": "error",
            "message": f"L·ªói server: {str(e)}"
        }), 500


@app.route('/api/video/status/<request_id>', methods=['GET'])
def get_video_status(request_id):
    """
    Ki·ªÉm tra tr·∫°ng th√°i x·ª≠ l√Ω video theo request_id
    
    Response:
    {
        "status": "completed|processing|error",
        "message": "...",
        "request_id": "...",
        ...
    }
    """
    redis_client = get_redis_client()
    if not redis_client:
        return jsonify({
            "status": "error",
            "message": "Kh√¥ng th·ªÉ k·∫øt n·ªëi Redis"
        }), 503
    
    try:
        result_key = f"request_id:{request_id}"
        result_json = redis_client.get(result_key)
        
        if result_json:
            result = json.loads(result_json)
            # Map status: "completed" -> "success" ƒë·ªÉ ph√π h·ª£p v·ªõi API response
            status = result.get("status", "unknown")
            if status == "completed":
                status = "success"
            
            return jsonify({
                "status": status,
                "message": result.get("message", ""),
                "request_id": result.get("request_id", request_id),
                "video_url": result.get("video_url", ""),
                "unique_id": result.get("unique_id"),
                "is_new": result.get("is_new", False),
                "similarity": result.get("similarity", 0.0),
                "added_at": result.get("added_at"),
                "cache_hit": result.get("cache_hit", False),
                "stats_before": result.get("stats_before"),
                "stats_after": result.get("stats_after"),
                "error": result.get("error")  # Th√™m error field n·∫øu c√≥
            }), 200
        else:
            # Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ - c√≥ th·ªÉ consumer ch∆∞a x·ª≠ l√Ω ho·∫∑c ch∆∞a ch·∫°y
            # Ki·ªÉm tra xem c√≥ message trong Kafka kh√¥ng (optional - ch·ªâ ƒë·ªÉ debug)
            console.print(f"[dim]‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ cho request_id: {request_id}[/dim]")
            console.print(f"[dim]   C√≥ th·ªÉ: 1) Consumer ch∆∞a x·ª≠ l√Ω 2) Consumer ch∆∞a ch·∫°y 3) Message ch∆∞a ƒë∆∞·ª£c consume[/dim]")
            return jsonify({
                "status": "processing",
                "message": "Video ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω ho·∫∑c request_id kh√¥ng t·ªìn t·∫°i. ƒê·∫£m b·∫£o video_consumer.py ƒëang ch·∫°y!",
                "request_id": request_id,
                "hint": "Ki·ªÉm tra: 1) video_consumer.py c√≥ ƒëang ch·∫°y kh√¥ng? 2) Kafka c√≥ ƒëang ch·∫°y kh√¥ng? 3) Consumer c√≥ nh·∫≠n ƒë∆∞·ª£c message t·ª´ Kafka kh√¥ng?",
                "note": "N·∫øu consumer ƒëang ch·∫°y, c√≥ th·ªÉ video ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω. Vui l√≤ng ƒë·ª£i th√™m."
            }), 200
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"L·ªói khi ki·ªÉm tra tr·∫°ng th√°i: {str(e)}",
            "request_id": request_id
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        # Test Kafka connection v·ªõi timeout chu·∫©n h√≥a
        from kafka import KafkaProducer
        test_producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            request_timeout_ms=KAFKA_REQUEST_TIMEOUT_MS,  # D√πng timeout chu·∫©n h√≥a
            max_block_ms=KAFKA_MAX_BLOCK_MS,  # D√πng timeout chu·∫©n h√≥a
            api_version=(0, 10, 1)
        )
        # Test b·∫±ng c√°ch list topics (nhanh h∆°n)
        test_producer.close(timeout=2)
        return jsonify({
            "status": "healthy",
            "kafka": "connected",
            "kafka_bootstrap_servers": KAFKA_BOOTSTRAP_SERVERS,
            "kafka_topic": KAFKA_TOPIC,
            "kafka_config": {
                "request_timeout_ms": KAFKA_REQUEST_TIMEOUT_MS,
                "max_block_ms": KAFKA_MAX_BLOCK_MS,
                "send_timeout_ms": KAFKA_SEND_TIMEOUT_MS,
                "retries": KAFKA_RETRIES
            }
        }), 200
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "kafka": "disconnected",
            "error": str(e),
            "hint": "Ki·ªÉm tra Kafka: docker ps | findstr kafka ho·∫∑c cd v√†o th∆∞ m·ª•c d·ª± √°n && docker-compose up -d"
        }), 503


@app.route('/', methods=['GET'])
def index():
    """API documentation"""
    return jsonify({
        "service": "Video Processing API",
        "version": "1.0.0",
        "endpoints": {
            "POST /api/video": "G·ª≠i video URL v√†o Kafka ƒë·ªÉ x·ª≠ l√Ω",
            "GET /api/health": "Ki·ªÉm tra tr·∫°ng th√°i service",
            "GET /": "API documentation"
        },
        "example_request": {
            "video_url": "https://example.com/video.mp4"
        }
    }), 200


if __name__ == '__main__':
    port = int(os.getenv("API_PORT", "5000"))
    host = os.getenv("API_HOST", "0.0.0.0")
    
    console.print(f"[bold cyan]üöÄ Starting Video Processing API on {host}:{port}[/bold cyan]")
    console.print(f"[cyan]üì° Kafka: {KAFKA_BOOTSTRAP_SERVERS}[/cyan]")
    console.print(f"[cyan]üì® Topic: {KAFKA_TOPIC}[/cyan]")
    
    app.run(host=host, port=port, debug=True)

