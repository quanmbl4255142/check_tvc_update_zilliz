"""
Flask API endpoint ƒë·ªÉ nh·∫≠n video URL v√† g·ª≠i v√†o Kafka
Endpoint: POST /api/video
"""

import os
import json
import uuid
import time
import redis
from datetime import datetime
from flask import Flask, request, jsonify
from kafka import KafkaProducer
from kafka.admin import KafkaAdminClient, NewTopic
from kafka.errors import TopicAlreadyExistsError
from rich.console import Console

console = Console()

app = Flask(__name__)

# Kafka configuration
KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092")
KAFKA_TOPIC = os.getenv("KAFKA_TOPIC", "video_processing")

# Redis configuration
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
REDIS_DB = int(os.getenv("REDIS_DB", "0"))

# Kafka timeout configuration - Import t·ª´ timeout_config
try:
    from timeout_config import (
        KAFKA_WAIT_READY_TIMEOUT,
        KAFKA_REQUEST_TIMEOUT_MS,
        KAFKA_MAX_BLOCK_MS,
        KAFKA_SEND_TIMEOUT_MS,
        KAFKA_RETRIES,
        KAFKA_RETRY_DELAY,
        REDIS_SOCKET_CONNECT_TIMEOUT,
        REDIS_SOCKET_TIMEOUT,
        REDIS_HEALTH_CHECK_INTERVAL,
        REDIS_CONNECTION_RETRIES,
        REDIS_RETRY_DELAY,
        RESULT_WAIT_TIMEOUT,
        RESULT_POLL_INTERVAL,
    )
except ImportError:
    # Fallback n·∫øu kh√¥ng c√≥ timeout_config
    KAFKA_WAIT_READY_TIMEOUT = int(os.getenv("KAFKA_WAIT_READY_TIMEOUT", "15"))
    KAFKA_REQUEST_TIMEOUT_MS = int(os.getenv("KAFKA_REQUEST_TIMEOUT_MS", "10000"))
    KAFKA_MAX_BLOCK_MS = int(os.getenv("KAFKA_MAX_BLOCK_MS", "10000"))
    KAFKA_SEND_TIMEOUT_MS = int(os.getenv("KAFKA_SEND_TIMEOUT_MS", "10000"))
    KAFKA_RETRIES = int(os.getenv("KAFKA_RETRIES", "3"))
    KAFKA_RETRY_DELAY = int(os.getenv("KAFKA_RETRY_DELAY", "2"))
    REDIS_SOCKET_CONNECT_TIMEOUT = int(os.getenv("REDIS_SOCKET_CONNECT_TIMEOUT", "5"))
    REDIS_SOCKET_TIMEOUT = int(os.getenv("REDIS_SOCKET_TIMEOUT", "5"))
    REDIS_HEALTH_CHECK_INTERVAL = int(os.getenv("REDIS_HEALTH_CHECK_INTERVAL", "30"))
    REDIS_CONNECTION_RETRIES = int(os.getenv("REDIS_CONNECTION_RETRIES", "5"))
    REDIS_RETRY_DELAY = float(os.getenv("REDIS_RETRY_DELAY", "2"))
    RESULT_WAIT_TIMEOUT = int(os.getenv("RESULT_WAIT_TIMEOUT", "30"))
    RESULT_POLL_INTERVAL = float(os.getenv("RESULT_POLL_INTERVAL", "0.5"))

# Initialize Kafka producer
producer = None

def ensure_topic_exists():
    """ƒê·∫£m b·∫£o topic t·ªìn t·∫°i - t·∫°o topic b·∫±ng AdminClient n·∫øu ch∆∞a c√≥"""
    from kafka.admin import KafkaAdminClient, NewTopic
    from kafka.errors import TopicAlreadyExistsError
    
    try:
        # Th·ª≠ t·∫°o topic b·∫±ng AdminClient tr∆∞·ªõc
        admin_client = KafkaAdminClient(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            client_id='video_api_admin',
            request_timeout_ms=min(KAFKA_REQUEST_TIMEOUT_MS, 15000),  # Max 15s
            api_version=(0, 10, 1)
        )
        
        # Ki·ªÉm tra topic c√≥ t·ªìn t·∫°i kh√¥ng
        try:
            topics = admin_client.list_topics()
            topic_list = list(topics) if isinstance(topics, (set, list)) else topics
            
            if KAFKA_TOPIC in topic_list:
                console.print(f"[green]‚úÖ Topic {KAFKA_TOPIC} already exists[/green]")
                admin_client.close()
                return True
        except Exception as list_error:
            console.print(f"[dim]Could not list topics: {list_error}[/dim]")
            # Continue to try creating topic
        
        # T·∫°o topic n·∫øu ch∆∞a t·ªìn t·∫°i
        console.print(f"[cyan]Creating topic {KAFKA_TOPIC}...[/cyan]")
        topic = NewTopic(
            name=KAFKA_TOPIC,
            num_partitions=1,
            replication_factor=1
        )
        
        try:
            admin_client.create_topics([topic], timeout_ms=15000)
            console.print(f"[green]‚úÖ Topic {KAFKA_TOPIC} created successfully[/green]")
            # ƒê·ª£i topic ƒë∆∞·ª£c t·∫°o xong
            time.sleep(2)
            admin_client.close()
            return True
        except TopicAlreadyExistsError:
            console.print(f"[green]‚úÖ Topic {KAFKA_TOPIC} already exists[/green]")
            admin_client.close()
            return True
        except Exception as create_error:
            console.print(f"[yellow]‚ö†Ô∏è  Could not create topic: {create_error}[/yellow]")
            admin_client.close()
            return False
            
    except Exception as e:
        console.print(f"[yellow]‚ö†Ô∏è  AdminClient error: {e}[/yellow]")
        console.print(f"[dim]   Topic will be auto-created on first message[/dim]")
        return False

def get_redis_client():
    """Lazy initialization of Redis client v·ªõi retry v√† connection pooling"""
    max_retries = REDIS_CONNECTION_RETRIES
    retry_delay = REDIS_RETRY_DELAY
    
    for attempt in range(max_retries):
        try:
            return redis.Redis(
                host=REDIS_HOST,
                port=REDIS_PORT,
                db=REDIS_DB,
                decode_responses=True,
                socket_connect_timeout=REDIS_SOCKET_CONNECT_TIMEOUT,
                socket_timeout=REDIS_SOCKET_TIMEOUT,
                socket_keepalive=True,
                health_check_interval=REDIS_HEALTH_CHECK_INTERVAL,
                retry_on_timeout=True,
                retry_on_error=[redis.ConnectionError, redis.TimeoutError]
            )
        except (redis.ConnectionError, redis.TimeoutError) as e:
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                retry_delay *= 1.5
            else:
                console.print(f"[yellow]‚ö†Ô∏è  Redis connection error after {max_retries} attempts: {e}[/yellow]")
                return None
        except Exception as e:
            console.print(f"[yellow]‚ö†Ô∏è  Redis connection error: {e}[/yellow]")
            return None

def wait_for_result(request_id: str, timeout: int, poll_interval: float):
    """
    ƒê·ª£i k·∫øt qu·∫£ t·ª´ consumer trong Redis
    
    Args:
        request_id: Request ID ƒë·ªÉ query
        timeout: Timeout t·ªëi ƒëa (gi√¢y)
        poll_interval: Kho·∫£ng th·ªùi gian gi·ªØa c√°c l·∫ßn poll (gi√¢y)
    
    Returns:
        dict: K·∫øt qu·∫£ t·ª´ consumer ho·∫∑c None n·∫øu timeout
    """
    redis_client = get_redis_client()
    if not redis_client:
        return None
    
    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            result_key = f"request_id:{request_id}"
            result_json = redis_client.get(result_key)
            
            if result_json:
                result = json.loads(result_json)
                # Chuy·ªÉn ƒë·ªïi response format ƒë·ªÉ ph√π h·ª£p v·ªõi API
                return {
                    "status": "success" if result.get("status") == "completed" else result.get("status"),
                    "message": result.get("message", ""),
                    "request_id": result.get("request_id", request_id),
                    "video_url": result.get("video_url", ""),
                    "unique_id": result.get("unique_id"),
                    "is_new": result.get("is_new", False),
                    "similarity": result.get("similarity", 0.0),
                    "added_at": result.get("added_at"),
                    "cache_hit": result.get("cache_hit", False),
                    "stats_before": result.get("stats_before"),
                    "stats_after": result.get("stats_after")
                }
        except Exception as e:
            console.print(f"[yellow]‚ö†Ô∏è  Error polling Redis: {e}[/yellow]")
        
        time.sleep(poll_interval)
    
    return None

# Cache ƒë·ªÉ tr√°nh check Kafka ready nhi·ªÅu l·∫ßn
_kafka_ready_cache = {"ready": False, "last_check": 0, "cache_ttl": 30}

def check_kafka_socket(host='localhost', port=9092, timeout=2):
    """Ki·ªÉm tra Kafka socket c√≥ s·∫µn s√†ng kh√¥ng (nhanh h∆°n AdminClient)"""
    import socket
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, port))
        sock.close()
        return result == 0
    except:
        return False

def wait_for_kafka_ready(max_wait=None, force_check=False):
    """ƒê·ª£i Kafka broker s·∫µn s√†ng - test b·∫±ng socket check v√† AdminClient"""
    from kafka.admin import KafkaAdminClient
    from kafka.errors import KafkaError
    import socket
    
    # S·ª≠ d·ª•ng timeout t·ª´ config n·∫øu kh√¥ng ch·ªâ ƒë·ªãnh
    if max_wait is None:
        max_wait = KAFKA_WAIT_READY_TIMEOUT
    
    # S·ª≠ d·ª•ng cache n·∫øu ƒë√£ check g·∫ßn ƒë√¢y
    current_time = time.time()
    if not force_check and _kafka_ready_cache["ready"]:
        if current_time - _kafka_ready_cache["last_check"] < _kafka_ready_cache["cache_ttl"]:
            return True
    
    # Parse bootstrap servers ƒë·ªÉ l·∫•y host v√† port
    bootstrap_host = "localhost"
    bootstrap_port = 9092
    try:
        if ":" in KAFKA_BOOTSTRAP_SERVERS:
            parts = KAFKA_BOOTSTRAP_SERVERS.split(":")
            bootstrap_host = parts[0].replace("localhost", "127.0.0.1")
            bootstrap_port = int(parts[1])
        else:
            bootstrap_host = KAFKA_BOOTSTRAP_SERVERS.replace("localhost", "127.0.0.1")
    except:
        pass
    
    start_time = time.time()
    attempt = 0
    
    # B∆∞·ªõc 1: Ki·ªÉm tra socket tr∆∞·ªõc (nhanh h∆°n)
    console.print(f"[dim]Checking Kafka socket at {bootstrap_host}:{bootstrap_port}...[/dim]")
    socket_ready = False
    socket_check_timeout = min(max_wait, 10)  # Max 10s ƒë·ªÉ check socket
    socket_start_time = time.time()
    
    while time.time() - socket_start_time < socket_check_timeout and not socket_ready:
        socket_ready = check_kafka_socket(bootstrap_host, bootstrap_port, timeout=2)
        if socket_ready:
            console.print(f"[green]‚úÖ Kafka socket is open[/green]")
            # ƒê·ª£i th√™m 5-10 gi√¢y ƒë·ªÉ Kafka ho√†n to√†n s·∫µn s√†ng (Zookeeper connection, metadata init)
            console.print(f"[dim]Waiting for Kafka broker to fully initialize (5-10 seconds)...[/dim]")
            time.sleep(5)  # ƒê·ª£i 5s ƒë·ªÉ Kafka kh·ªüi t·∫°o metadata
            break
        time.sleep(1)
    
    if not socket_ready:
        console.print(f"[red]‚ùå Kafka socket is not open at {bootstrap_host}:{bootstrap_port}[/red]")
        console.print(f"[yellow]üí° H√£y ki·ªÉm tra Kafka ƒëang ch·∫°y: docker ps | findstr kafka[/yellow]")
        console.print(f"[yellow]üí° Ho·∫∑c kh·ªüi ƒë·ªông Kafka: docker-compose up -d[/yellow]")
        _kafka_ready_cache["ready"] = False
        _kafka_ready_cache["last_check"] = time.time()
        return False
    
    # B∆∞·ªõc 2: Test b·∫±ng Producer thay v√¨ AdminClient (reliable h∆°n)
    # Producer c√≥ th·ªÉ k·∫øt n·ªëi ngay c·∫£ khi AdminClient fail
    attempt = 0
    producer_check_start = time.time()
    remaining_time = max_wait - (time.time() - start_time)
    
    # ƒê·∫£m b·∫£o c√≤n √≠t nh·∫•t 10s ƒë·ªÉ test Producer
    if remaining_time < 10:
        console.print(f"[yellow]‚ö†Ô∏è  Kh√¥ng ƒë·ªß th·ªùi gian ƒë·ªÉ test Producer (c√≤n {remaining_time:.1f}s)[/yellow]")
        console.print(f"[yellow]üí° Kafka socket m·ªü nh∆∞ng broker c√≥ th·ªÉ ch∆∞a s·∫µn s√†ng. S·∫Ω th·ª≠ t·∫°o Producer tr·ª±c ti·∫øp.[/yellow]")
        _kafka_ready_cache["ready"] = False
        _kafka_ready_cache["last_check"] = time.time()
        return False  # Nh∆∞ng v·∫´n cho ph√©p t·∫°o Producer
    
    while time.time() - producer_check_start < remaining_time:
        try:
            attempt += 1
            console.print(f"[dim]Testing Kafka broker readiness with Producer (attempt {attempt})...[/dim]")
            
            # Test b·∫±ng c√°ch t·∫°o Producer v√† th·ª≠ fetch metadata
            # Producer th∆∞·ªùng reliable h∆°n AdminClient
            test_producer = KafkaProducer(
                bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
                request_timeout_ms=min(KAFKA_REQUEST_TIMEOUT_MS, 15000),
                max_block_ms=min(KAFKA_MAX_BLOCK_MS, 15000),
                api_version=(0, 10, 1)
            )
            
            # ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ Producer kh·ªüi t·∫°o
            time.sleep(1)
            
            # Th·ª≠ fetch metadata b·∫±ng c√°ch g·ªçi partitions_for (non-blocking n·∫øu metadata ƒë√£ c√≥)
            # Ho·∫∑c th·ª≠ send m·ªôt dummy message v·ªõi timeout ng·∫Øn
            try:
                partitions = test_producer.partitions_for(KAFKA_TOPIC)
                if partitions is not None:
                    console.print(f"[dim]   Metadata available: {len(partitions) if partitions else 0} partition(s)[/dim]")
            except:
                # Metadata ch∆∞a c√≥, nh∆∞ng Producer ƒë√£ t·∫°o ƒë∆∞·ª£c - c√≥ nghƒ©a l√† Kafka s·∫µn s√†ng
                pass
            
            test_producer.close(timeout=2)
            
            # Update cache
            _kafka_ready_cache["ready"] = True
            _kafka_ready_cache["last_check"] = time.time()
            total_time = time.time() - start_time
            console.print(f"[green]‚úÖ Kafka broker is ready! (after {attempt} attempt(s), {total_time:.1f}s)[/green]")
            return True
        except (KafkaError, Exception) as e:
            # Ch∆∞a s·∫µn s√†ng, ƒë·ª£i th√™m
            elapsed = time.time() - producer_check_start
            remaining = remaining_time - elapsed
            if remaining > 5:  # C√≤n √≠t nh·∫•t 5s th√¨ retry
                wait_time = min(3, remaining / 2)  # ƒê·ª£i 3s ho·∫∑c m·ªôt n·ª≠a th·ªùi gian c√≤n l·∫°i
                error_msg = str(e)[:100]
                console.print(f"[yellow]‚ö†Ô∏è  Broker not ready yet (attempt {attempt}): {error_msg}[/yellow]")
                console.print(f"[dim]   Waiting {wait_time:.1f}s before retry...[/dim]")
                time.sleep(wait_time)
            else:
                # Kh√¥ng c√≤n th·ªùi gian ƒë·ªÉ retry
                break
    
    # Update cache - kh√¥ng ready
    _kafka_ready_cache["ready"] = False
    _kafka_ready_cache["last_check"] = time.time()
    console.print(f"[yellow]‚ö†Ô∏è  Kafka socket is open but broker may not be fully ready after {max_wait}s[/yellow]")
    console.print(f"[yellow]üí° Kafka c√≥ th·ªÉ ƒëang kh·ªüi ƒë·ªông ho·∫∑c c√≥ v·∫•n ƒë·ªÅ. H√£y th·ª≠:[/yellow]")
    console.print(f"[yellow]   1. Ki·ªÉm tra Kafka logs: docker logs kafka[/yellow]")
    console.print(f"[yellow]   2. Ki·ªÉm tra Zookeeper: docker logs zookeeper[/yellow]")
    console.print(f"[yellow]   3. Restart Kafka: docker restart kafka[/yellow]")
    console.print(f"[yellow]   4. ƒê·ª£i 30-60 gi√¢y r·ªìi th·ª≠ l·∫°i[/yellow]")
    return False

def get_kafka_producer():
    """Lazy initialization of Kafka producer v·ªõi retry logic v√† timeout h·ª£p l√Ω"""
    global producer
    if producer is None:
        import time
        max_retries = KAFKA_RETRIES
        retry_delay = KAFKA_RETRY_DELAY
        
        for attempt in range(max_retries + 1):  # +1 ƒë·ªÉ c√≥ t·ªïng (max_retries + 1) l·∫ßn th·ª≠
            try:
                # ƒê·ª£i Kafka s·∫µn s√†ng tr∆∞·ªõc khi t·∫°o producer (ch·ªâ l·∫ßn ƒë·∫ßu)
                # Nh∆∞ng kh√¥ng fail n·∫øu check fail - v·∫´n cho ph√©p t·∫°o Producer
                if attempt == 0:
                    console.print(f"[cyan]‚è≥ ƒê·ª£i Kafka broker s·∫µn s√†ng (timeout: {KAFKA_WAIT_READY_TIMEOUT}s)...[/cyan]")
                    kafka_ready = wait_for_kafka_ready(max_wait=KAFKA_WAIT_READY_TIMEOUT, force_check=(attempt == 0))
                    if not kafka_ready:
                        console.print(f"[yellow]‚ö†Ô∏è  Kafka readiness check failed, but will try to create Producer anyway...[/yellow]")
                        console.print(f"[dim]   Producer will retry automatically when sending messages[/dim]")
                
                # ƒê·∫£m b·∫£o topic t·ªìn t·∫°i tr∆∞·ªõc khi t·∫°o Producer
                # ƒêi·ªÅu n√†y gi√∫p Producer kh√¥ng ph·∫£i fetch metadata l√¢u
                try:
                    ensure_topic_exists()
                except Exception as topic_error:
                    console.print(f"[yellow]‚ö†Ô∏è  Could not ensure topic exists: {topic_error}[/yellow]")
                    console.print(f"[dim]   Topic will be auto-created on first message[/dim]")
                
                producer = KafkaProducer(
                    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
                    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                    key_serializer=lambda k: k.encode('utf-8') if k else None,
                    acks=0,  # Fire-and-forget ƒë·ªÉ tr√°nh block (message v·∫´n ƒë∆∞·ª£c g·ª≠i)
                    retries=max_retries,  # S·ªë l·∫ßn retry t·ª´ config
                    max_in_flight_requests_per_connection=1,  # ƒê·∫£m b·∫£o th·ª© t·ª± message
                    request_timeout_ms=KAFKA_REQUEST_TIMEOUT_MS,  # Timeout chu·∫©n h√≥a
                    metadata_max_age_ms=300000,  # 5 ph√∫t - refresh metadata
                    connections_max_idle_ms=540000,  # 9 ph√∫t - gi·ªØ connection
                    linger_ms=0,  # G·ª≠i ngay (kh√¥ng batch)
                    batch_size=0,  # Kh√¥ng batch
                    max_block_ms=10000,  # Gi·∫£m xu·ªëng 10s ƒë·ªÉ tr√°nh block qu√° l√¢u
                    api_version=(0, 10, 1)  # Ch·ªâ ƒë·ªãnh API version
                )
                
                # Kh√¥ng pre-fetch metadata n·ªØa - ƒë·ªÉ Producer t·ª± fetch khi send
                # V·ªõi max_block_ms=10s, Producer s·∫Ω ch·ªâ block t·ªëi ƒëa 10s khi fetch metadata
                # N·∫øu kh√¥ng fetch ƒë∆∞·ª£c trong 10s, Producer s·∫Ω raise exception nh∆∞ng message v·∫´n ƒë∆∞·ª£c queue
                console.print(f"[dim]   Metadata will be fetched automatically on first send (max_block: 10s)[/dim]")
                
                console.print(f"[green]‚úÖ Kafka producer created v·ªõi acks=0 (fire-and-forget)[/green]")
                console.print(f"[dim]   Config: request_timeout={KAFKA_REQUEST_TIMEOUT_MS}ms, max_block=10000ms, retries={max_retries}[/dim]")
                break  # Th√†nh c√¥ng, tho√°t kh·ªèi retry loop
            except Exception as e:
                if attempt < max_retries:
                    console.print(f"[yellow]‚ö†Ô∏è  Attempt {attempt + 1}/{max_retries + 1} failed: {e}[/yellow]")
                    console.print(f"[dim]   Retrying in {retry_delay} seconds...[/dim]")
                    time.sleep(retry_delay)
                else:
                    console.print(f"[red]‚ùå Failed to connect to Kafka after {max_retries + 1} attempts: {e}[/red]")
                    console.print(f"[yellow]üí° ƒê·∫£m b·∫£o Kafka ƒëang ch·∫°y: docker-compose up -d[/yellow]")
                    raise
    return producer


@app.route('/api/video', methods=['POST'])
def add_video():
    """
    Nh·∫≠n video URL v√† g·ª≠i v√†o Kafka
    
    Request body:
    {
        "video_url": "https://example.com/video.mp4"
    }
    
    Response:
    {
        "status": "success",
        "message": "Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o Kafka",
        "request_id": "uuid",
        "video_url": "https://example.com/video.mp4",
        "timestamp": "2024-01-01T00:00:00"
    }
    """
    try:
        data = request.get_json()
        
        if not data or 'video_url' not in data:
            return jsonify({
                "status": "error",
                "message": "Thi·∫øu video_url trong request body"
            }), 400
        
        video_url = data['video_url'].strip()
        
        if not video_url:
            return jsonify({
                "status": "error",
                "message": "video_url kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
            }), 400
        
        # URL validation - ki·ªÉm tra format URL h·ª£p l·ªá
        import re
        from urllib.parse import urlparse
        
        # Basic URL validation
        url_pattern = re.compile(
            r'^https?://'  # http:// or https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        
        if not url_pattern.match(video_url):
            return jsonify({
                "status": "error",
                "message": "video_url kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng URL h·ª£p l·ªá"
            }), 400
        
        # Parse URL ƒë·ªÉ ki·ªÉm tra scheme v√† host
        try:
            parsed = urlparse(video_url)
            if not parsed.scheme or not parsed.netloc:
                return jsonify({
                    "status": "error",
                    "message": "video_url ph·∫£i c√≥ scheme (http/https) v√† host"
                }), 400
        except Exception as e:
            return jsonify({
                "status": "error",
                "message": f"video_url kh√¥ng h·ª£p l·ªá: {str(e)}"
            }), 400
        
        # Generate unique request ID
        request_id = str(uuid.uuid4())
        timestamp = datetime.now().isoformat()
        
        # Create message payload
        message = {
            "request_id": request_id,
            "video_url": video_url,
            "timestamp": timestamp,
            "status": "pending"
        }
        
        # Send to Kafka - Fire and forget (kh√¥ng ƒë·ª£i confirmation ƒë·ªÉ tr√°nh timeout)
        try:
            console.print(f"[cyan]üì§ Sending video to Kafka: {video_url[:60]}...[/cyan]")
            console.print(f"[dim]Request ID: {request_id}[/dim]")
            
            # Th·ª≠ l·∫•y producer (c√≥ th·ªÉ fail n·∫øu Kafka ch∆∞a s·∫µn s√†ng)
            try:
                kafka_producer = get_kafka_producer()
            except Exception as producer_error:
                # N·∫øu kh√¥ng t·∫°o ƒë∆∞·ª£c producer, v·∫´n tr·∫£ v·ªÅ "processing"
                console.print(f"[yellow]‚ö†Ô∏è  Kh√¥ng th·ªÉ t·∫°o Kafka producer: {producer_error}[/yellow]")
                console.print(f"[dim]   Tr·∫£ v·ªÅ status 'processing' - UI s·∫Ω poll status endpoint[/dim]")
                return jsonify({
                    "status": "processing",
                    "message": "Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o h√†ng ƒë·ª£i, ƒëang ch·ªù Kafka s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra l·∫°i sau.",
                    "request_id": request_id,
                    "video_url": video_url,
                    "timestamp": timestamp,
                    "kafka_status": "not_ready",
                    "check_status_url": f"/api/video/status/{request_id}"
                }), 202
            
            # G·ª≠i message - v·ªõi acks=0, Producer s·∫Ω kh√¥ng block v√† tr·∫£ v·ªÅ ngay
            try:
                console.print(f"[cyan]üì§ Sending message to Kafka topic: {KAFKA_TOPIC}...[/cyan]")
                console.print(f"[dim]   Request ID: {request_id}[/dim]")
                
                # G·ª≠i message - v·ªõi max_block_ms=10s, n·∫øu kh√¥ng fetch ƒë∆∞·ª£c metadata trong 10s s·∫Ω raise exception
                # Nh∆∞ng v·ªõi acks=0, Producer s·∫Ω queue message v√† retry trong background
                try:
                    future = kafka_producer.send(
                        KAFKA_TOPIC,
                        value=message,
                        key=request_id
                    )
                    
                    # V·ªõi acks=0, kh√¥ng c·∫ßn ƒë·ª£i future.get() - message ƒë√£ ƒë∆∞·ª£c queue
                    # Producer s·∫Ω t·ª± retry trong background n·∫øu c√≥ l·ªói
                    console.print(f"[green]‚úÖ Message queued to Kafka (fire-and-forget)[/green]")
                    console.print(f"[dim]   Message s·∫Ω ƒë∆∞·ª£c g·ª≠i trong background[/dim]")
                    console.print(f"[dim]   Producer s·∫Ω t·ª± retry n·∫øu c√≥ l·ªói[/dim]")
                    
                    return jsonify({
                        "status": "processing",
                        "message": "Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o Kafka v√† ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω",
                        "request_id": request_id,
                        "video_url": video_url,
                        "timestamp": timestamp,
                        "kafka_topic": KAFKA_TOPIC,
                        "check_status_url": f"/api/video/status/{request_id}",
                        "note": "ƒê·∫£m b·∫£o video_consumer.py ƒëang ch·∫°y ƒë·ªÉ x·ª≠ l√Ω message. Message ƒëang ƒë∆∞·ª£c g·ª≠i trong background."
                    }), 202  # 202 Accepted - ƒëang x·ª≠ l√Ω
                    
                except Exception as send_error:
                    error_str = str(send_error).lower()
                    # N·∫øu l√† metadata timeout, v·∫´n tr·∫£ v·ªÅ processing v√¨ Producer c√≥ th·ªÉ retry
                    if "metadata" in error_str or "timeout" in error_str:
                        console.print(f"[yellow]‚ö†Ô∏è  Metadata timeout khi g·ª≠i message: {send_error}[/yellow]")
                        console.print(f"[dim]   Producer s·∫Ω retry trong background[/dim]")
                        console.print(f"[dim]   Tr·∫£ v·ªÅ processing ƒë·ªÉ UI c√≥ th·ªÉ poll status[/dim]")
                        
                        return jsonify({
                            "status": "processing",
                            "message": "Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o h√†ng ƒë·ª£i. Kafka ƒëang fetch metadata, message s·∫Ω ƒë∆∞·ª£c g·ª≠i trong background.",
                            "request_id": request_id,
                            "video_url": video_url,
                            "timestamp": timestamp,
                            "kafka_status": "metadata_fetching",
                            "kafka_error": str(send_error),
                            "check_status_url": f"/api/video/status/{request_id}",
                            "note": "Producer ƒëang fetch metadata. Message s·∫Ω ƒë∆∞·ª£c g·ª≠i t·ª± ƒë·ªông khi metadata s·∫µn s√†ng."
                        }), 202
                    else:
                        # L·ªói kh√°c
                        console.print(f"[red]‚ùå Error sending to Kafka: {send_error}[/red]")
                        import traceback
                        traceback.print_exc()
                        
                        return jsonify({
                            "status": "error",
                            "message": f"Kh√¥ng th·ªÉ g·ª≠i message v√†o Kafka: {str(send_error)}",
                            "request_id": request_id,
                            "video_url": video_url,
                            "timestamp": timestamp,
                            "kafka_error": str(send_error),
                            "hint": "Ki·ªÉm tra Kafka ƒëang ch·∫°y: docker ps | findstr kafka"
                        }), 500
                        
            except Exception as send_error:
                error_str = str(send_error).lower()
                console.print(f"[red]‚ùå Error sending to Kafka: {send_error}[/red]")
                import traceback
                traceback.print_exc()
                
                # N·∫øu l√† metadata/connection error, tr·∫£ v·ªÅ processing ƒë·ªÉ UI c√≥ th·ªÉ retry
                if "metadata" in error_str or "timeout" in error_str or "node" in error_str or "connection" in error_str:
                    return jsonify({
                        "status": "processing",
                        "message": "Kafka broker ch∆∞a s·∫µn s√†ng. Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o h√†ng ƒë·ª£i, ƒëang ch·ªù Kafka. Vui l√≤ng ki·ªÉm tra Kafka v√† th·ª≠ l·∫°i sau.",
                        "request_id": request_id,
                        "video_url": video_url,
                        "timestamp": timestamp,
                        "kafka_status": "not_ready",
                        "kafka_error": str(send_error),
                        "check_status_url": f"/api/video/status/{request_id}",
                        "troubleshooting": [
                            "1. Ki·ªÉm tra Kafka ƒëang ch·∫°y: docker ps | findstr kafka",
                            "2. Kh·ªüi ƒë·ªông Kafka: docker-compose up -d",
                            "3. ƒê·ª£i 30-60 gi√¢y ƒë·ªÉ Kafka kh·ªüi ƒë·ªông ho√†n to√†n",
                            "4. Ki·ªÉm tra logs: docker logs kafka"
                        ]
                    }), 202
                else:
                    return jsonify({
                        "status": "error",
                        "message": f"Kh√¥ng th·ªÉ g·ª≠i message v√†o Kafka: {str(send_error)}",
                        "request_id": request_id,
                        "video_url": video_url,
                        "timestamp": timestamp,
                        "kafka_error": str(send_error),
                        "hint": "Ki·ªÉm tra Kafka ƒëang ch·∫°y: docker ps | findstr kafka"
                    }), 500
            
        except Exception as e:
            error_str = str(e).lower()
            console.print(f"[red]‚ùå Failed to send to Kafka: {e}[/red]")
            import traceback
            traceback.print_exc()
            
            # N·∫øu l√† connection/metadata error, tr·∫£ v·ªÅ processing ƒë·ªÉ UI c√≥ th·ªÉ retry
            if "metadata" in error_str or "timeout" in error_str or "node" in error_str or "connection" in error_str:
                console.print(f"[yellow]üí° Kafka kh√¥ng s·∫µn s√†ng. Tr·∫£ v·ªÅ processing ƒë·ªÉ UI c√≥ th·ªÉ retry sau.[/yellow]")
                return jsonify({
                    "status": "processing",
                    "message": "Kafka broker ch∆∞a s·∫µn s√†ng. Video ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o h√†ng ƒë·ª£i, ƒëang ch·ªù Kafka. Vui l√≤ng ki·ªÉm tra Kafka v√† th·ª≠ l·∫°i sau.",
                    "request_id": request_id,
                    "video_url": video_url,
                    "timestamp": timestamp,
                    "kafka_status": "not_ready",
                    "kafka_error": str(e),
                    "check_status_url": f"/api/video/status/{request_id}",
                    "troubleshooting": [
                        "1. Ki·ªÉm tra Kafka: docker ps | findstr kafka",
                        "2. Kh·ªüi ƒë·ªông Kafka: docker-compose up -d",
                        "3. ƒê·ª£i 30-60 gi√¢y ƒë·ªÉ Kafka kh·ªüi ƒë·ªông",
                        "4. Ki·ªÉm tra logs: docker logs kafka"
                    ]
                }), 202
            else:
                # L·ªói kh√°c
                return jsonify({
                    "status": "error",
                    "message": f"L·ªói khi g·ª≠i v√†o Kafka: {str(e)}",
                    "request_id": request_id,
                    "video_url": video_url,
                    "timestamp": timestamp,
                    "kafka_error": str(e),
                    "hint": "Ki·ªÉm tra Kafka ƒëang ch·∫°y: docker ps | findstr kafka"
                }), 500
            
    except Exception as e:
        console.print(f"[red]‚ùå API Error: {e}[/red]")
        return jsonify({
            "status": "error",
            "message": f"L·ªói server: {str(e)}"
        }), 500


@app.route('/api/video/status/<request_id>', methods=['GET'])
def get_video_status(request_id):
    """
    Ki·ªÉm tra tr·∫°ng th√°i x·ª≠ l√Ω video theo request_id
    
    Response:
    {
        "status": "completed|processing|error",
        "message": "...",
        "request_id": "...",
        ...
    }
    """
    redis_client = get_redis_client()
    if not redis_client:
        return jsonify({
            "status": "error",
            "message": "Kh√¥ng th·ªÉ k·∫øt n·ªëi Redis"
        }), 503
    
    try:
        result_key = f"request_id:{request_id}"
        result_json = redis_client.get(result_key)
        
        if result_json:
            result = json.loads(result_json)
            # Map status: "completed" -> "success" ƒë·ªÉ ph√π h·ª£p v·ªõi API response
            status = result.get("status", "unknown")
            if status == "completed":
                status = "success"
            
            return jsonify({
                "status": status,
                "message": result.get("message", ""),
                "request_id": result.get("request_id", request_id),
                "video_url": result.get("video_url", ""),
                "unique_id": result.get("unique_id"),
                "is_new": result.get("is_new", False),
                "similarity": result.get("similarity", 0.0),
                "added_at": result.get("added_at"),
                "cache_hit": result.get("cache_hit", False),
                "stats_before": result.get("stats_before"),
                "stats_after": result.get("stats_after"),
                "error": result.get("error")  # Th√™m error field n·∫øu c√≥
            }), 200
        else:
            # Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ - c√≥ th·ªÉ consumer ch∆∞a x·ª≠ l√Ω ho·∫∑c ch∆∞a ch·∫°y
            # Ki·ªÉm tra xem c√≥ message trong Kafka kh√¥ng (optional - ch·ªâ ƒë·ªÉ debug)
            console.print(f"[dim]‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ cho request_id: {request_id}[/dim]")
            console.print(f"[dim]   C√≥ th·ªÉ: 1) Consumer ch∆∞a x·ª≠ l√Ω 2) Consumer ch∆∞a ch·∫°y 3) Message ch∆∞a ƒë∆∞·ª£c consume[/dim]")
            return jsonify({
                "status": "processing",
                "message": "Video ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω ho·∫∑c request_id kh√¥ng t·ªìn t·∫°i. ƒê·∫£m b·∫£o video_consumer.py ƒëang ch·∫°y!",
                "request_id": request_id,
                "hint": "Ki·ªÉm tra: 1) video_consumer.py c√≥ ƒëang ch·∫°y kh√¥ng? 2) Kafka c√≥ ƒëang ch·∫°y kh√¥ng? 3) Consumer c√≥ nh·∫≠n ƒë∆∞·ª£c message t·ª´ Kafka kh√¥ng?",
                "note": "N·∫øu consumer ƒëang ch·∫°y, c√≥ th·ªÉ video ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω. Vui l√≤ng ƒë·ª£i th√™m."
            }), 200
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"L·ªói khi ki·ªÉm tra tr·∫°ng th√°i: {str(e)}",
            "request_id": request_id
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        # Test Kafka connection v·ªõi timeout chu·∫©n h√≥a
        from kafka import KafkaProducer
        test_producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            request_timeout_ms=KAFKA_REQUEST_TIMEOUT_MS,  # D√πng timeout chu·∫©n h√≥a
            max_block_ms=KAFKA_MAX_BLOCK_MS,  # D√πng timeout chu·∫©n h√≥a
            api_version=(0, 10, 1)
        )
        # Test b·∫±ng c√°ch list topics (nhanh h∆°n)
        test_producer.close(timeout=2)
        return jsonify({
            "status": "healthy",
            "kafka": "connected",
            "kafka_bootstrap_servers": KAFKA_BOOTSTRAP_SERVERS,
            "kafka_topic": KAFKA_TOPIC,
            "kafka_config": {
                "request_timeout_ms": KAFKA_REQUEST_TIMEOUT_MS,
                "max_block_ms": KAFKA_MAX_BLOCK_MS,
                "send_timeout_ms": KAFKA_SEND_TIMEOUT_MS,
                "retries": KAFKA_RETRIES
            }
        }), 200
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "kafka": "disconnected",
            "error": str(e),
            "hint": "Ki·ªÉm tra Kafka: docker ps | findstr kafka ho·∫∑c cd v√†o th∆∞ m·ª•c d·ª± √°n && docker-compose up -d"
        }), 503


@app.route('/', methods=['GET'])
def index():
    """API documentation"""
    return jsonify({
        "service": "Video Processing API",
        "version": "1.0.0",
        "endpoints": {
            "POST /api/video": "G·ª≠i video URL v√†o Kafka ƒë·ªÉ x·ª≠ l√Ω",
            "GET /api/health": "Ki·ªÉm tra tr·∫°ng th√°i service",
            "GET /": "API documentation"
        },
        "example_request": {
            "video_url": "https://example.com/video.mp4"
        }
    }), 200


if __name__ == '__main__':
    port = int(os.getenv("API_PORT", "5000"))
    host = os.getenv("API_HOST", "0.0.0.0")
    
    console.print(f"[bold cyan]üöÄ Starting Video Processing API on {host}:{port}[/bold cyan]")
    console.print(f"[cyan]üì° Kafka: {KAFKA_BOOTSTRAP_SERVERS}[/cyan]")
    console.print(f"[cyan]üì® Topic: {KAFKA_TOPIC}[/cyan]")
    
    app.run(host=host, port=port, debug=True)

